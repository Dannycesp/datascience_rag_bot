{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3a2d5c9-f0f6-4413-8965-37d2a939e6ec",
   "metadata": {},
   "source": [
    "The dataset is in this link: https://www.kaggle.com/datasets/hserdaraltan/1000-data-science-concepts/data\n",
    "and the kaggle command is:  kaggle datasets download -d hserdaraltan/1000-data-science-concepts\n",
    "for simplicity i download it manually and save as ./data/data.csv as for downloading with kaggle command an API KEY is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f35b1666-5393-458a-b747-177c1a1525ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import minsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f98df4-326c-4a0f-95a3-2441e1ced3ca",
   "metadata": {},
   "source": [
    "## Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acee6281-a506-4dc0-9f82-8b2ad48346ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92bdbd8d-eef7-4f2a-a55b-37e7c17f17b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ebfa883-0ea5-41f9-aab6-ed4b1fca3841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the project we limit the dataset to the first 200 records of the dataset. For those 200 we have made\n",
    "#3 questions that we saved in ground_truth_data.csv\n",
    "documents = documents[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb71055b-9d7d-4fd3-8987-f39f935ec11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- First 1 entries ---\n",
      "{'id': 1, 'Question': 'What is under-fitting and overfitting in machine learning?', 'Answer': \"Underfitting is when a model is too simple, and overfitting is when it's too complex, making it perform poorly on new data.\"}\n",
      "\n",
      "--- Last {n} entries ---\n",
      "{'id': 200, 'Question': 'What is the difference between a generative and discriminative model?', 'Answer': 'Generative models learn data categories, while discriminative models learn category distinctions. Discriminative models generally outperform generative models in classification tasks.'}\n"
     ]
    }
   ],
   "source": [
    "def display_head_and_tail(dataset, n=1):\n",
    "    \"\"\"Display the first and last `n` entries of the dataset.\"\"\"\n",
    "    # Display first `n` entries (head)\n",
    "    print(f\"--- First {n} entries ---\")\n",
    "    for item in dataset[:n]:  # Slicing to get the first `n` items\n",
    "        print(item)\n",
    "    \n",
    "    print(\"\\n--- Last {n} entries ---\")\n",
    "    for item in dataset[-n:]:  # Slicing to get the last `n` items\n",
    "        print(item)\n",
    "\n",
    "display_head_and_tail(documents, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c73ab96-2845-442f-acdc-bc243c0554c6",
   "metadata": {},
   "source": [
    "#no need for this as data.csv has been already prepared with id\n",
    "def add_id_to_dataset(dataset):\n",
    "    \"\"\"Add 'id' to each item in the dataset, with 'id' being the first key.\"\"\"\n",
    "    for idx, item in enumerate(dataset, start=1):\n",
    "        # Create a new dictionary with 'id' first, followed by the rest of the keys\n",
    "        item = {'id': idx, **item}\n",
    "        dataset[idx - 1] = item  # Update the dataset with the new order\n",
    "    return dataset\n",
    "\n",
    "# Add 'id' to each dictionary, with 'id' as the first key\n",
    "documents = add_id_to_dataset(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a0b02a4-bda2-4acf-bd6e-b76a9daccc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is under-fitting and overfitting in machi...</td>\n",
       "      <td>Underfitting is when a model is too simple, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Can you explain what a false positive and a fa...</td>\n",
       "      <td>A false positive incorrectly indicates a condi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Clarify the concept of Phase IV.</td>\n",
       "      <td>Phase IV studies, also known as post-marketing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>What is semi-supervised learning described in ...</td>\n",
       "      <td>Semi-supervised learning integrates both label...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Discuss the parallelization of training in gra...</td>\n",
       "      <td>Parallelizing training of a gradient boosting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>1066</td>\n",
       "      <td>Define the ACID property in SQL and its signif...</td>\n",
       "      <td>ACID principles maintain database integrity by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>1067</td>\n",
       "      <td>What are the different types of data warehouses?</td>\n",
       "      <td>Data warehouses vary by scope and function, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>1068</td>\n",
       "      <td>What are the key stages in a data mining project?</td>\n",
       "      <td>A data mining project starts with understandin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>1069</td>\n",
       "      <td>What is information extraction?</td>\n",
       "      <td>Information extraction systematically identifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>1070</td>\n",
       "      <td>Describe kernel support vector machines (KSVMs).</td>\n",
       "      <td>Kernel Support Vector Machines (KSVMs) are a c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1070 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           Question  \\\n",
       "0        1  What is under-fitting and overfitting in machi...   \n",
       "1        2  Can you explain what a false positive and a fa...   \n",
       "2        3                   Clarify the concept of Phase IV.   \n",
       "3        4  What is semi-supervised learning described in ...   \n",
       "4        5  Discuss the parallelization of training in gra...   \n",
       "...    ...                                                ...   \n",
       "1065  1066  Define the ACID property in SQL and its signif...   \n",
       "1066  1067   What are the different types of data warehouses?   \n",
       "1067  1068  What are the key stages in a data mining project?   \n",
       "1068  1069                    What is information extraction?   \n",
       "1069  1070   Describe kernel support vector machines (KSVMs).   \n",
       "\n",
       "                                                 Answer  \n",
       "0     Underfitting is when a model is too simple, an...  \n",
       "1     A false positive incorrectly indicates a condi...  \n",
       "2     Phase IV studies, also known as post-marketing...  \n",
       "3     Semi-supervised learning integrates both label...  \n",
       "4     Parallelizing training of a gradient boosting ...  \n",
       "...                                                 ...  \n",
       "1065  ACID principles maintain database integrity by...  \n",
       "1066  Data warehouses vary by scope and function, wi...  \n",
       "1067  A data mining project starts with understandin...  \n",
       "1068  Information extraction systematically identifi...  \n",
       "1069  Kernel Support Vector Machines (KSVMs) are a c...  \n",
       "\n",
       "[1070 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cb61ed6-815f-47a6-8e5d-39ddca63982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a8ad749-5266-4a24-ae50-b35d1aae7ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=['Question', 'Answer'],  # Fields where text-based searches will be performed\n",
    "    keyword_fields=['id']  # If you have an 'id' or unique identifier for each entry\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d734c998-f4a5-4390-9708-6c1edda23348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x73a294f0ba60>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f70bc03-575d-4576-8b1d-f82462feb485",
   "metadata": {},
   "source": [
    "## RAG flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b199ddf5-6d9a-485e-9ed3-5dcb1a5c0ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "#source ./bin/activate from project folder before to activate environment\n",
    "load_dotenv()  # Loads the variables from .env file\n",
    "\n",
    "# Now you can access the API_KEY\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "#print(api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0eef0c9-3e59-4b02-9f49-57f7ae78e84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "#client = OpenAI(api_key=api_key)\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96687ff0-3348-4743-a56a-786127c84fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2450e48b-b4e3-4555-9e01-5674c3ff0404",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Your role is to answer questions about datascience based on the database with questions and asnwers about datascience.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION, where the CONTEXT is just our question and answer database, that you have below.\n",
    "If the context is not sufficient for giving a response, your response will be \"Not enough context in questions and answers database\".\n",
    "Even if you have more information outside the context, do not use it and base your answer only in the context.\n",
    "Write only the answer itself without any further comments.\n",
    "Be precise and concise and try using as few words as required to give a meaninful answer, with the minimum words possible.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "entry_template = \"\"\"\n",
    "Question: {Question}\n",
    "Answer: {Answer}\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + entry_template.format(**doc) + \"\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c89a49b5-972c-4fc9-be43-8ab3916563c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model='llama3.1:8b'\n",
    "model_ollama = 'llama3.1:8b'\n",
    "model_openai = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9722a500-b947-4f0e-8d89-07201a362951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e45a6aa-1ca9-4649-abd9-fb1253da087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d1d1c70-a21d-4af7-8168-22215303687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, model):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    #print(prompt)\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3537254c-7300-4515-ba0a-41c7ced25913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 183,\n",
       "  'Question': 'What tools are used for training NLP models?',\n",
       "  'Answer': 'Tools for training NLP models include NLTK for language processing tasks, spaCy for advanced NLP, and PyTorch-NLP for deep learning in NLP.'},\n",
       " {'id': 153,\n",
       "  'Question': 'What are the tools of AI?',\n",
       "  'Answer': 'AI tools range from libraries like Scikit Learn for machine learning to TensorFlow and Keras for deep learning, providing environments for developing AI models.'},\n",
       " {'id': 126,\n",
       "  'Question': 'What are the common ETL tools used during data warehousing activities?',\n",
       "  'Answer': 'In data warehousing, popular ETL (Extract, Transform, Load) tools include Informatica for enterprise data integration, Talend for data management and integration, Ab Initio for handling large data volumes, Oracle Data Integrator for combining with Oracle databases, Skyvia for cloud data integration, SSIS for SQL Server integration, Pentaho for business analytics, and Xplenty for ETL processes in the cloud.'},\n",
       " {'id': 57,\n",
       "  'Question': 'What are the different algorithms used in machine learning?',\n",
       "  'Answer': 'Machine learning algorithms are chosen based on the task: regression (Linear Regression), classification (Logistic Regression, Naive Bayes), and both (Decision Trees, SVM). Unsupervised learning uses algorithms like K-means for clustering and PCA for dimensionality reduction.'},\n",
       " {'id': 11,\n",
       "  'Question': 'What is the Naive Bayes algorithm, and how is it used in NLP?',\n",
       "  'Answer': 'Naive Bayes predicts text tags based on probabilities, often used in NLP for classification tasks.'},\n",
       " {'id': 116,\n",
       "  'Question': 'Which Python libraries are frequently used in machine learning?',\n",
       "  'Answer': 'Common ML libraries include Pandas for data manipulation, NumPy for numerical operations, SciPy for scientific computing, Sklearn for ML algorithms, and TensorFlow for deep learning.'},\n",
       " {'id': 53,\n",
       "  'Question': 'What are the different kernels in SVM?',\n",
       "  'Answer': 'Support Vector Machines use kernels to transform data into higher dimensions for classification. The main kernels are Linear (simple linear boundaries), Polynomial (complex regions), Radial Basis Function (RBF, for non-linear boundaries), and Sigmoid (similar to neural networks).'},\n",
       " {'id': 74,\n",
       "  'Question': 'What are generative adversarial networks (GAN)?',\n",
       "  'Answer': 'Generative Adversarial Networks are a class of artificial intelligence models composed of two networks, the generative and the discriminative, which are trained simultaneously to generate new, synthetic instances of data that are indistinguishable from real data.'},\n",
       " {'id': 80,\n",
       "  'Question': 'Which Python libraries are you familiar with?',\n",
       "  'Answer': 'Python libraries like NumPy, Pandas, and Scikit-Learn are widely used for data manipulation and machine learning tasks, while Keras and TensorFlow are popular for deep learning applications.'},\n",
       " {'id': 96,\n",
       "  'Question': 'What are project deliverables?',\n",
       "  'Answer': \"Project deliverables are the tangible or intangible outcomes of a project that fulfill the project's objectives and are handed over to the client or stakeholder upon completion.\"}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'What tools are used in datascience?'\n",
    "\n",
    "busqueda = search(query)\n",
    "busqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aba093cb-6024-4034-9ae0-20ecffc7461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = rag(query,model_ollama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d14aa61c-c548-4c2e-9621-278b7200c07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NLTK, spaCy, PyTorch-NLP, Scikit Learn, TensorFlow, Keras, Informatica, Talend, Ab Initio, Oracle Data Integrator, Skyvia, SSIS, Pentaho, Xplenty, Pandas, NumPy, SciPy, Sklearn, and TensorFlow.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa7392a-9b5b-4421-974b-52cd7d261b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#already generated in notebook for evaluation with llama3.1\n",
    "#def generate_questions(doc):\n",
    "    prompt = prompt_template.format(**doc)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    json_response = response.choices[0].message.content\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9100bd80-431d-4990-98f7-0ef5ed0fd174",
   "metadata": {},
   "source": [
    "## Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b222152e-525a-40c0-a071-9530d4eb5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data already in a csv, created in notebook evaluation_data_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a88433ad-dcc1-4455-a0df-3006b43c52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question = pd.read_csv('../data/ground-truth-retrieval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6525af2-4c66-4f4a-88c2-91e0b6b8dc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What happens when a machine learning model is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>How does overfitting affect a model's performa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Can a model be too complex, and if so, what ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>What are the implications of a test result tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>How does a false indication of a condition's a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           question\n",
       "0   1  What happens when a machine learning model is ...\n",
       "1   1  How does overfitting affect a model's performa...\n",
       "2   1  Can a model be too complex, and if so, what ar...\n",
       "3   2  What are the implications of a test result tha...\n",
       "4   2  How does a false indication of a condition's a..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e41a0aa-8f78-4aeb-b334-dd963d63a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = df_question.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c86b03ae-5a68-4ac4-9314-00b521b56272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'question': 'What happens when a machine learning model is too simple?'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ad9e893-c880-4af5-b6df-4a9b2806d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d576457-2365-49bc-a573-df306e999c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bde9bbdd-f1a3-4e73-8538-d2591ed159c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49033d89-9f85-4374-a379-28b4dd9ec14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2dd4e92-ca43-4b0c-ae47-6ec89b83a622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:00<00:00, 1168.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.95, 'mrr': 0.8056335978835977}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_search(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95137144-7060-4e4c-aba5-359de3085144",
   "metadata": {},
   "source": [
    "## Finding the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "387e641c-6592-4e4f-b191-1e5ca7598f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = df_question[:100]\n",
    "df_test = df_question[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d51edf19-2b80-4870-887a-3bc0f3c47d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What happens when a machine learning model is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>How does overfitting affect a model's performa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Can a model be too complex, and if so, what ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>What are the implications of a test result tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>How does a false indication of a condition's a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>32</td>\n",
       "      <td>How do stakeholders determine the order of ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>33</td>\n",
       "      <td>What techniques can reduce overfitting in SVM ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>33</td>\n",
       "      <td>How does dimensionality reduction impact compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>33</td>\n",
       "      <td>Can high-dimensional datasets benefit from pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>34</td>\n",
       "      <td>What makes Apache Spark faster than MapReduce?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                           question\n",
       "0    1  What happens when a machine learning model is ...\n",
       "1    1  How does overfitting affect a model's performa...\n",
       "2    1  Can a model be too complex, and if so, what ar...\n",
       "3    2  What are the implications of a test result tha...\n",
       "4    2  How does a false indication of a condition's a...\n",
       "..  ..                                                ...\n",
       "95  32  How do stakeholders determine the order of ful...\n",
       "96  33  What techniques can reduce overfitting in SVM ...\n",
       "97  33  How does dimensionality reduction impact compu...\n",
       "98  33  Can high-dimensional datasets benefit from pre...\n",
       "99  34     What makes Apache Spark faster than MapReduce?\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a95c044-df61-4cb6-84a9-19ff9e1ef107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def simple_optimize(param_ranges, objective_function, n_iterations=10):\n",
    "    best_params = None\n",
    "    best_score = float('-inf')  # Assuming we're minimizing. Use float('-inf') if maximizing.\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        # Generate random parameters\n",
    "        current_params = {}\n",
    "        for param, (min_val, max_val) in param_ranges.items():\n",
    "            if isinstance(min_val, int) and isinstance(max_val, int):\n",
    "                current_params[param] = random.randint(min_val, max_val)\n",
    "            else:\n",
    "                current_params[param] = random.uniform(min_val, max_val)\n",
    "        \n",
    "        # Evaluate the objective function\n",
    "        current_score = objective_function(current_params)\n",
    "        \n",
    "        # Update best if current is better\n",
    "        if current_score > best_score:  # Change to > if maximizing\n",
    "            best_score = current_score\n",
    "            best_params = current_params\n",
    "    \n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6535225c-aa11-4875-895e-f84f2020083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_val = df_validation.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33d2c962-b56a-4f1d-892a-1b84e89f4f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query, boost=None):\n",
    "    if boost is None:\n",
    "        boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d61d688-45a0-40c9-bf5a-e87ad778ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ranges = {\n",
    "    'Question': (0.0, 3.0),\n",
    "    'Answer': (0.0, 3.0),\n",
    "   \n",
    "}\n",
    "\n",
    "def objective(boost_params):\n",
    "    def search_function(q):\n",
    "        return minsearch_search(q['question'], boost_params)\n",
    "\n",
    "    results = evaluate(gt_val, search_function)\n",
    "    return results['mrr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85f903c6-9c07-4399-9cca-e12bda23e7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1093.63it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1146.83it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1147.29it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1103.09it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1199.06it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1204.16it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1209.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1175.53it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1179.29it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1182.28it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1186.64it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1183.05it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1191.45it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1190.12it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1185.23it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1184.48it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1203.08it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1182.22it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1185.73it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1213.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Question': 0.9712610571824632, 'Answer': 2.4119285092818314},\n",
       " 0.9043452380952379)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_optimize(param_ranges, objective, n_iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d4609490-a334-4dd6-ac7e-f6f7122fab51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1131.42it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1176.52it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1145.97it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1128.54it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1038.12it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1170.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1198.11it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1205.03it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1187.02it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1192.51it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1191.73it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1189.23it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1183.65it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1191.41it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1181.11it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1196.68it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1222.03it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1183.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1177.34it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1186.57it/s]\n"
     ]
    }
   ],
   "source": [
    "best_params, best_score = simple_optimize(param_ranges, objective, n_iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "59b3d7d8-df8d-4efe-b6b1-58b8c20bba47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Question': 0.5579461443001708, 'Answer': 1.4578273881638246} 0.9043452380952379\n"
     ]
    }
   ],
   "source": [
    "print(best_params, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e11a1b9-9375-4c24-bfb3-0170ce82187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_improved(query, best_params):\n",
    "    boost = {\n",
    "        'Question': best_params['Question'],\n",
    "        'Answer': best_params['Answer']\n",
    "       \n",
    "    }\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "#evaluate(ground_truth, lambda q: minsearch_improved(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1211336b-272a-4384-a494-691f5b188887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:00<00:00, 1189.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.985, 'mrr': 0.9059900793650794}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_improved(q['question'],best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de669d5-f9a4-4da0-b533-2781204ece3b",
   "metadata": {},
   "source": [
    "## RAG evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ab3ae9a-8639-4244-ada3-90d321f0ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_template = \"\"\"\n",
    "You have to evaluate a Retrieval Augmented Generation System (RAG).\n",
    "Your task consists in analyzing the relevance of the answer generated by a large language model (llm) to a given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks with this structure:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\n",
    " The final answer must be just the json object without any further comments before or after.\n",
    "\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb3a0f2a-a232-4864-bf43-c93578667914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "63b07234-15f1-4470-b28c-d1051054ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'question': 'Can a model be too complex, and if so, what are the consequences?'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "458abc6c-5820-4c7e-8ca6-10f09e4c552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=ground_truth[2]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2285c20b-3b51-4b5a-9e1a-e93a00104fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can a model be too complex, and if so, what are the consequences?'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cbfee5e1-e61e-4524-8714-1d407ed0273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_llm=rag(question,model_ollama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f18b5df6-6905-43c1-98a1-abb47984902c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, a model can be too complex, leading to overfitting. Consequences include poor performance on new data.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "311e3d42-30a4-4fe7-906c-c3806442bc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have to evaluate a Retrieval Augmented Generation System (RAG).\n",
      "Your task consists in analyzing the relevance of the answer generated by a large language model (llm) to a given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: Can a model be too complex, and if so, what are the consequences?\n",
      "Generated Answer: Yes, a model can be too complex, leading to overfitting. Consequences include poor performance on new data.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks with this structure:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n",
      "\n",
      " The final answer must be just the json object without any further comments before or after.\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt2_template.format(question=question, answer_llm=answer_llm)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c081e711-4e5c-4cd4-bc8d-79a29c1f1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6da1bf76-7670-4723-847d-15aad4a5d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_question.sample(n=100, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "98a38031-1e2b-4134-bc88-6d9e857771f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_sample.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2551470a-3fe7-4c22-98d8-d425e6fa56c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 149, 'question': 'List common NLP tasks supported by Apache OpenNLP.'},\n",
       " {'id': 135,\n",
       "  'question': 'What happens when you use the break statement in a loop?'},\n",
       " {'id': 170,\n",
       "  'question': 'Can you describe a scenario where patterns and relationships are discovered without prior knowledge of the outcome?'},\n",
       " {'id': 152,\n",
       "  'question': 'How is an S-curve used for trend analysis and forecasting?'},\n",
       " {'id': 68,\n",
       "  'question': 'What is a range of values that likely contains the population parameter?'},\n",
       " {'id': 8,\n",
       "  'question': 'Can you explain how mutable and immutable data affect argument passing in Python?'},\n",
       " {'id': 139,\n",
       "  'question': 'How does econometrics help understand economic relationships?'},\n",
       " {'id': 183,\n",
       "  'question': 'List the primary tools utilized in deep learning for natural language processing.'},\n",
       " {'id': 23,\n",
       "  'question': 'What is the average difference between predicted and actual values in a dataset?'},\n",
       " {'id': 56, 'question': 'What is a concise way to create lists in Python?'},\n",
       " {'id': 112,\n",
       "  'question': 'Which biases in sampling methods can lead to incorrect population representation?'},\n",
       " {'id': 110,\n",
       "  'question': 'What is the process to refine and deploy an effective model?'},\n",
       " {'id': 1,\n",
       "  'question': 'What happens when a machine learning model is too simple?'},\n",
       " {'id': 178, 'question': 'What is the purpose of Information Retrieval?'},\n",
       " {'id': 78,\n",
       "  'question': 'How do data mining and data warehousing differ in their approaches to data analysis?'},\n",
       " {'id': 67, 'question': 'How does the Cox model handle censored data?'},\n",
       " {'id': 50,\n",
       "  'question': 'What does statistical power measure in hypothesis testing?'},\n",
       " {'id': 158, 'question': 'How does ETL help in preparing data for analysis?'},\n",
       " {'id': 151,\n",
       "  'question': \"How can you ensure a model's performance is not overly dependent on the training data?\"},\n",
       " {'id': 166,\n",
       "  'question': 'How does AdaGrad scale parameters according to past gradients?'},\n",
       " {'id': 5,\n",
       "  'question': 'What options are available in XGBoost to utilize GPUs for faster training?'},\n",
       " {'id': 171,\n",
       "  'question': 'What is the primary goal of recommendation algorithms?'},\n",
       " {'id': 90,\n",
       "  'question': 'How does unsupervised learning handle unlabeled data?'},\n",
       " {'id': 120,\n",
       "  'question': 'How does a model determine the category of a new observation?'},\n",
       " {'id': 97,\n",
       "  'question': 'In search functions, what technique is used to identify non-identical strings?'},\n",
       " {'id': 162,\n",
       "  'question': 'What types of statistical biases can lead to incorrect conclusions?'},\n",
       " {'id': 144, 'question': 'What is PCA used for in data analysis?'},\n",
       " {'id': 16,\n",
       "  'question': 'What aggregate functions can be applied to each group using groupby?'},\n",
       " {'id': 75,\n",
       "  'question': 'Which natural language processing library is written in Java?'},\n",
       " {'id': 62,\n",
       "  'question': 'Can you describe the process of building a tree-based model?'},\n",
       " {'id': 144, 'question': 'How does PCA simplify complex datasets?'},\n",
       " {'id': 103,\n",
       "  'question': 'What is the main goal of the Probably Approximately Correct (PAC) learning framework?'},\n",
       " {'id': 41,\n",
       "  'question': 'What statistical methods are used in linear regression?'},\n",
       " {'id': 84,\n",
       "  'question': 'How does stratified sampling ensure proportional representation of various subgroups?'},\n",
       " {'id': 38,\n",
       "  'question': 'What are the primary differences between collaborative filtering and content-based filtering?'},\n",
       " {'id': 98,\n",
       "  'question': 'What is the primary goal of adjusting weights and biases based on computed gradients?'},\n",
       " {'id': 22, 'question': 'Why is the IQR useful in statistical analysis?'},\n",
       " {'id': 160,\n",
       "  'question': 'What is the purpose of a classification threshold in logistic regression?'},\n",
       " {'id': 192,\n",
       "  'question': 'What is the primary goal of managing model complexity in machine learning?'},\n",
       " {'id': 150,\n",
       "  'question': 'What is the threshold for an effect to be considered statistically significant?'},\n",
       " {'id': 112,\n",
       "  'question': 'What are the common pitfalls that can skew results when collecting data?'},\n",
       " {'id': 70,\n",
       "  'question': 'What tools enable data engineers to process, analyze, and prepare data efficiently?'},\n",
       " {'id': 140,\n",
       "  'question': 'In what scenarios would you use the % operator to compute remainders in Python?'},\n",
       " {'id': 45,\n",
       "  'question': 'What is an autonomous entity in AI that perceives surroundings through sensors?'},\n",
       " {'id': 17,\n",
       "  'question': 'How do wrapper methods iteratively add or remove features based on model performance?'},\n",
       " {'id': 106,\n",
       "  'question': 'What ensemble learning method uses numerous decision trees to reduce overfitting?'},\n",
       " {'id': 86,\n",
       "  'question': 'What advanced methods can be employed for complex pattern recognition in sequential data?'},\n",
       " {'id': 153, 'question': 'What environments enable AI model development?'},\n",
       " {'id': 20,\n",
       "  'question': 'How does a basic neural network learn patterns from data?'},\n",
       " {'id': 142, 'question': 'What is the Bag of Words model used for?'},\n",
       " {'id': 145, 'question': 'How does DeepFace classify faces accurately?'},\n",
       " {'id': 55,\n",
       "  'question': 'What method is used during model training to selectively calculate probabilities for all positive class instances and a random subset of negative ones?'},\n",
       " {'id': 14,\n",
       "  'question': 'Which statistical models are robust against anomalies in time series data?'},\n",
       " {'id': 185,\n",
       "  'question': 'How do knowledge engineers capture human expertise?'},\n",
       " {'id': 180,\n",
       "  'question': 'In what ways can virtual assistants benefit from NLP capabilities?'},\n",
       " {'id': 197,\n",
       "  'question': 'What search strategy involves running two simultaneous searches?'},\n",
       " {'id': 182,\n",
       "  'question': 'In what way do distributed systems like Hadoop benefit from organizing data storage efficiently?'},\n",
       " {'id': 46,\n",
       "  'question': \"What statistical methods are used to determine if a sample's characteristics can be generalized to the entire population?\"},\n",
       " {'id': 21,\n",
       "  'question': 'What transformation does softmax apply to neural network outputs?'},\n",
       " {'id': 132,\n",
       "  'question': 'List three examples of applications where weak AI can be effectively used.'},\n",
       " {'id': 166,\n",
       "  'question': 'What algorithm adjusts learning rates for each parameter individually?'},\n",
       " {'id': 168,\n",
       "  'question': 'What parameter is used to determine the number of trees in a random forest?'},\n",
       " {'id': 31, 'question': 'What patterns can models identify in data?'},\n",
       " {'id': 78,\n",
       "  'question': 'What role do data mining and data warehousing play in enabling informed decision-making?'},\n",
       " {'id': 66,\n",
       "  'question': 'What is the purpose of using conditional formatting in a dataset?'},\n",
       " {'id': 198,\n",
       "  'question': 'Can gradient descent methods converge to the same point under varying cost functions?'},\n",
       " {'id': 6,\n",
       "  'question': 'What can be reused in different programs when using a Python module?'},\n",
       " {'id': 135,\n",
       "  'question': 'What are the three main loop control statements in programming?'},\n",
       " {'id': 187,\n",
       "  'question': 'What statistical properties must variables have for linear regression to hold?'},\n",
       " {'id': 104,\n",
       "  'question': 'What is the typical deviation of data values from their mean, as expressed by standard deviation?'},\n",
       " {'id': 136,\n",
       "  'question': \"How do rotations affect a CNN's performance on images?\"},\n",
       " {'id': 173,\n",
       "  'question': 'What ensures interpretability of machine learning models when dealing with categorical data?'},\n",
       " {'id': 31,\n",
       "  'question': \"What tasks are facilitated by exploring data's inherent structure?\"},\n",
       " {'id': 98,\n",
       "  'question': 'How do gradients influence adjustments to weights and biases in a model?'},\n",
       " {'id': 156, 'question': 'What does the survival function represent?'},\n",
       " {'id': 10,\n",
       "  'question': 'What visual tool provides insights into data concentration and frequency?'},\n",
       " {'id': 125,\n",
       "  'question': 'Which search strategies can be employed to optimize hyperparameters?'},\n",
       " {'id': 29, 'question': 'How do NLP systems process text and speech data?'},\n",
       " {'id': 195,\n",
       "  'question': 'What is a reference point for comparing model performance?'},\n",
       " {'id': 148,\n",
       "  'question': 'How does data mining differ from data profiling in terms of analysis goals?'},\n",
       " {'id': 83,\n",
       "  'question': 'How does the input layer process raw data in a neural network?'},\n",
       " {'id': 58,\n",
       "  'question': 'What impact does variance have on statistical analyses and decision-making?'},\n",
       " {'id': 167,\n",
       "  'question': \"How do Amazon's product recommendations work without needing to know the features of items themselves?\"},\n",
       " {'id': 198,\n",
       "  'question': 'What happens when gradient descent methods are applied with different initial conditions?'},\n",
       " {'id': 155, 'question': 'What is TensorFlow, a machine learning framework?'},\n",
       " {'id': 187,\n",
       "  'question': 'Under what conditions does linear regression assume errors are distributed?'},\n",
       " {'id': 30,\n",
       "  'question': 'Describe the format in which datasets are typically stored.'},\n",
       " {'id': 96, 'question': 'What tangible outcomes are expected from a project?'},\n",
       " {'id': 87,\n",
       "  'question': 'How does RMSE measure the dispersion or variability of data points around a regression line?'},\n",
       " {'id': 58,\n",
       "  'question': 'How is variance related to data points around the mean?'},\n",
       " {'id': 196,\n",
       "  'question': 'What enables neural networks to learn complex relationships between inputs and outputs?'},\n",
       " {'id': 80,\n",
       "  'question': 'What Python libraries are commonly used for data manipulation?'},\n",
       " {'id': 190,\n",
       "  'question': 'What is the primary purpose of incorporating covariates into an analysis using ANCOVA?'},\n",
       " {'id': 54,\n",
       "  'question': 'How can selecting non-representative participants affect the validity of study conclusions?'},\n",
       " {'id': 2,\n",
       "  'question': \"What are the implications of a test result that incorrectly suggests a condition's presence?\"},\n",
       " {'id': 147,\n",
       "  'question': 'How do generalized linear models differ from traditional linear regression?'},\n",
       " {'id': 4, 'question': 'What is semi-supervised learning?'},\n",
       " {'id': 64, 'question': 'What factors influence chart creation?'},\n",
       " {'id': 125,\n",
       "  'question': 'List different methods to find optimal hyperparameters for a model.'},\n",
       " {'id': 173,\n",
       "  'question': 'How are categories represented in one-hot encoding?'}]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd780a32-43aa-4063-963a-a575a6e58ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f311c421-ff0e-4f1a-b6f2-387151969e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION TO PARSE THE OUTPUTS FROM THE LLM WHEN IT DOES NOT PRODUCE PURE JSON CONSISTENTLY (usually open source models)\n",
    "#after many iterations this is the function that works better when the output of the llm is not correctly formatted\n",
    "#and we have more control of which outputs failed as we save the errors and the program continue even if some\n",
    "#outputs failed\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "def robust_json_loads(s):\n",
    "    \"\"\"\n",
    "    Attempts to parse a JSON string, fixing common errors if parsing fails.\n",
    "\n",
    "    Parameters:\n",
    "    s (str): The JSON string to parse.\n",
    "\n",
    "    Returns:\n",
    "    tuple: (success (bool), data (dict or None), error_message (str or None))\n",
    "    \"\"\"\n",
    "    original_s = s  # Keep a copy of the original string\n",
    "\n",
    "    # First, attempt to parse the input string directly\n",
    "    try:\n",
    "        data = json.loads(s)\n",
    "        return (True, data, None)\n",
    "    except json.JSONDecodeError:\n",
    "        pass  # Proceed to cleaning steps if parsing fails\n",
    "\n",
    "    # Step 1: Strip wrapping backticks and language specifiers\n",
    "    s = s.strip()\n",
    "    s = re.sub(r'^```[a-zA-Z]*\\s*', '', s)  # Remove starting triple backticks and optional language\n",
    "    s = re.sub(r'```$', '', s)              # Remove ending triple backticks\n",
    "    s = s.strip('`')                        # Remove any remaining backticks\n",
    "\n",
    "    # Step 2: Remove any text before the first '{' or '['\n",
    "    start_idx = re.search(r'[\\{\\[]', s)\n",
    "    if not start_idx:\n",
    "        error_message = \"No JSON object could be detected in the input.\"\n",
    "        return (False, None, error_message)\n",
    "    s = s[start_idx.start():]\n",
    "\n",
    "    # Step 3: Remove any text after the last '}' or ']'\n",
    "    end_idx = max(s.rfind('}'), s.rfind(']'))\n",
    "    if end_idx == -1:\n",
    "        error_message = \"No JSON object could be detected in the input.\"\n",
    "        return (False, None, error_message)\n",
    "    s = s[:end_idx+1]\n",
    "\n",
    "    # Step 4: Remove extraneous characters after the JSON content\n",
    "    # Remove any characters after the last closing brace/bracket\n",
    "    s = re.sub(r'([\\}\\]])[\\s\\S]*$', r'\\1', s)\n",
    "\n",
    "    # Step 5: Remove extraneous characters before the JSON content\n",
    "    # Remove any characters before the first opening brace/bracket\n",
    "    s = re.sub(r'^[\\s\\S]*?([\\{\\[])', r'\\1', s)\n",
    "\n",
    "    # Step 6: Replace single quotes with double quotes for keys and values\n",
    "    # Avoid changing single quotes inside double-quoted strings\n",
    "    s = re.sub(\n",
    "        r'(?<=[:\\{\\[,])\\s*\\'([^\\']*)\\'\\s*(?=[:,\\}\\]])',\n",
    "        r'\"\\1\"',\n",
    "        s\n",
    "    )\n",
    "\n",
    "    # Step 7: Remove trailing commas before closing braces/brackets\n",
    "    s = re.sub(r',\\s*(\\}|\\])', r'\\1', s)\n",
    "\n",
    "    # Step 8: Balance brackets and braces if necessary\n",
    "    def balance_characters(s, open_char, close_char):\n",
    "        opens = s.count(open_char)\n",
    "        closes = s.count(close_char)\n",
    "        if opens > closes:\n",
    "            s += close_char * (opens - closes)\n",
    "        elif closes > opens:\n",
    "            s = open_char * (closes - opens) + s\n",
    "        return s\n",
    "\n",
    "    s = balance_characters(s, '{', '}')\n",
    "    s = balance_characters(s, '[', ']')\n",
    "\n",
    "    # Step 9: Remove unescaped control characters\n",
    "    # Control characters are not allowed in JSON strings\n",
    "    s = re.sub(r'[\\x00-\\x1F]+', '', s)\n",
    "\n",
    "    # Step 10: Final check to remove extra double quotes at the end of strings in arrays\n",
    "    # This targets the specific case you mentioned\n",
    "    s = re.sub(r'(\".*?\")\"+(?=\\s*[\\],}])', r'\\1', s)\n",
    "\n",
    "    # Step 11: Attempt to parse the cleaned string\n",
    "    try:\n",
    "        data = json.loads(s)\n",
    "    except json.JSONDecodeError as e:\n",
    "        error_message = f\"Error parsing JSON after cleaning: {e}\"\n",
    "        return (False, None, error_message)\n",
    "\n",
    "    # Validate that the parsed data contains the expected 'questions' key\n",
    "    if not isinstance(data, dict) or 'questions' not in data:\n",
    "        error_message = \"Parsed JSON does not contain 'questions' key.\"\n",
    "        return (False, None, error_message)\n",
    "\n",
    "    # Check that 'questions' is a non-empty list\n",
    "    if not isinstance(data['questions'], list) or not data['questions']:\n",
    "        error_message = \"'questions' key is empty or not a list.\"\n",
    "        return (False, None, error_message)\n",
    "\n",
    "    # Parsing and validation successful\n",
    "    return (True, data, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534de1e-91ac-4fd2-bb29-ad2c02feb3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b19dc128-646b-484d-81d6-66a42dda7afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a range of values that likely contains the population parameter?'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2c7d19ff-4c46-4355-83f0-2dcc3d8d1eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A confidence interval is a range of values that likely contains the population parameter with a certain level of confidence, accounting for sample variability.'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944fbcbf-cb33-4384-b514-7faac5d52add",
   "metadata": {},
   "source": [
    "#the answers to evaluate are generated with ollama models for cost and efficiency. \n",
    "llama3.1:8b       \t\t4.7 GB\t26  \t\n",
    "qwen2-math:7b     \t\t4.4 GB\t2   \t\n",
    "wizard-math:latest\t\t4.1 GB\t5   \t\n",
    "phi3:latest       \t\t2.2 GB\t5   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9b84ad3d-8c8f-4b63-8fb4-a6f6715bfadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after trying several options with small samples we choose llama3.1 as the generator of answers and judge for the\n",
    "#first round, and below the same answers will be evaluated by gpt-4o-mini\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "88d6c27e-178e-49e7-bd7b-703cb27067b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1='llama3.1:8b'\n",
    "model_2='llama3.1:8b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a66cdc62-803c-4c79-a687-581788fe1d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [06:03<00:00,  3.64s/it]\n"
     ]
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question,model_1) #here the model that creates the question\n",
    "    #answer_llm = robust_json_loads(answer_llm)\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt, model_2) #here the model as judge that decides the relevance of the questions\n",
    "    #evaluation = json.loads(evaluation)\n",
    "    #evaluation = robust_json_loads(evaluation)\n",
    "    # Call the parsing function robust_json_loads\n",
    "    success, evaluation, error_message = robust_json_loads(evaluation)\n",
    "\n",
    "    evaluations.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "52791e66-19b8-4691-8bee-efd78540d3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'id': 149,\n",
       "   'question': 'List common NLP tasks supported by Apache OpenNLP.'},\n",
       "  'Tokenization, parsing, named entity recognition.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by listing specific NLP tasks supported by Apache OpenNLP, making it highly relevant.'}),\n",
       " ({'id': 135,\n",
       "   'question': 'What happens when you use the break statement in a loop?'},\n",
       "  'Break exits loop prematurely.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question about what happens when using the break statement in a loop.'}),\n",
       " ({'id': 170,\n",
       "   'question': 'Can you describe a scenario where patterns and relationships are discovered without prior knowledge of the outcome?'},\n",
       "  'Patterns and relationships are discovered without prior knowledge of the outcome when using techniques like transfer learning in computer vision, where a model developed for one task is repurposed on another related task.',\n",
       "  {'Relevance': 'PARTLY_RELEVANT',\n",
       "   'Explanation': \"The generated answer partially addresses the question by mentioning techniques like transfer learning, but it doesn't fully describe a scenario where patterns and relationships are discovered without prior knowledge of the outcome in a general sense.\"}),\n",
       " ({'id': 152,\n",
       "   'question': 'How is an S-curve used for trend analysis and forecasting?'},\n",
       "  'The S-curve serves as a visual tool for analyzing and forecasting trends, guiding strategic decision-making and resource allocation.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the use of an S-curve in trend analysis and forecasting, providing a clear connection to the question.'}),\n",
       " ({'id': 68,\n",
       "   'question': 'What is a range of values that likely contains the population parameter?'},\n",
       "  'A confidence interval is a range of values that likely contains the population parameter with a certain level of confidence, accounting for sample variability.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by providing a clear definition of what likely contains the population parameter, which is a confidence interval.'}),\n",
       " ({'id': 8,\n",
       "   'question': 'Can you explain how mutable and immutable data affect argument passing in Python?'},\n",
       "  'In Python, function arguments are passed by assignment, which can appear as call by value for immutable data and call by reference for mutable data, depending on whether the objects involved are mutable or immutable.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by explaining how mutable and immutable data affect argument passing in Python, providing a clear and concise explanation.'}),\n",
       " ({'id': 139,\n",
       "   'question': 'How does econometrics help understand economic relationships?'},\n",
       "  'Econometrics uses statistical techniques to analyze economic data, helping to understand economic relationships and predict future trends based on historical data.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by explaining how econometrics helps understand economic relationships, making it highly relevant.'}),\n",
       " ({'id': 183,\n",
       "   'question': 'List the primary tools utilized in deep learning for natural language processing.'},\n",
       "  'NLTK, spaCy, and PyTorch-NLP.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by listing specific tools used in deep learning for natural language processing.'}),\n",
       " ({'id': 23,\n",
       "   'question': 'What is the average difference between predicted and actual values in a dataset?'},\n",
       "  'The average difference between predicted and actual values in a dataset is quantified by Mean Absolute Error (MAE).',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by providing a specific metric (MAE) that quantifies the average difference between predicted and actual values in a dataset.'}),\n",
       " ({'id': 56, 'question': 'What is a concise way to create lists in Python?'},\n",
       "  'list() or array() functions.',\n",
       "  {'Relevance': 'PARTLY_RELEVANT',\n",
       "   'Explanation': 'The generated answer is partially relevant because it mentions list() function, which is related to creating lists in Python. However, it also mentions array() function, which is not directly related to the question.'}),\n",
       " ({'id': 112,\n",
       "   'question': 'Which biases in sampling methods can lead to incorrect population representation?'},\n",
       "  'Sampling biases include selection bias, undercoverage bias, and survivorship bias, all of which can skew results and misrepresent populations.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by listing specific biases in sampling methods that can lead to incorrect population representation.'}),\n",
       " ({'id': 110,\n",
       "   'question': 'What is the process to refine and deploy an effective model?'},\n",
       "  'Model development progresses through various stages, starting with defining the business problem and understanding data requirements. Exploratory analysis and data preparation ensure data quality and understanding. Feature engineering optimizes input variables for modeling. Data split separates training and testing datasets. Model building, testing, and implementation iteratively refine and deploy the model. Performance tracking monitors model effectiveness over time, ensuring continuous improvement and alignment with evolving business needs.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer provides a detailed and accurate description of the process to refine and deploy an effective model, directly addressing the question.'}),\n",
       " ({'id': 1,\n",
       "   'question': 'What happens when a machine learning model is too simple?'},\n",
       "  'When a machine learning model is too simple, it performs poorly on new data.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the consequence of a machine learning model being too simple, which is closely related to the question.'}),\n",
       " ({'id': 178, 'question': 'What is the purpose of Information Retrieval?'},\n",
       "  'Information Retrieval stores and retrieves data, akin to database searches.',\n",
       "  {'Relevance': 'PARTLY_RELEVANT',\n",
       "   'Explanation': \"The generated answer partially addresses the question by mentioning data retrieval, but it doesn't fully capture the purpose of Information Retrieval, which is a broader concept that involves searching and filtering large amounts of information.\"}),\n",
       " ({'id': 78,\n",
       "   'question': 'How do data mining and data warehousing differ in their approaches to data analysis?'},\n",
       "  'Data mining uncovers patterns and relationships in data, whereas data warehousing integrates and stores data for analysis purposes.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the difference between data mining and data warehousing, providing a clear distinction in their approaches to data analysis.'}),\n",
       " ({'id': 67, 'question': 'How does the Cox model handle censored data?'},\n",
       "  'The Cox model handles censored data.',\n",
       "  {'Relevance': 'PARTLY_RELEVANT',\n",
       "   'Explanation': 'The generated answer is relevant in that it mentions censored data, but it does not provide any explanation on how the Cox model handles it.'}),\n",
       " ({'id': 50,\n",
       "   'question': 'What does statistical power measure in hypothesis testing?'},\n",
       "  'The probability of correctly rejecting the null hypothesis when a true effect exists.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the concept of statistical power in hypothesis testing, which is exactly what the question asks about.'}),\n",
       " ({'id': 158, 'question': 'How does ETL help in preparing data for analysis?'},\n",
       "  'ETL helps prepare data for analysis by taking data from one or more sources, converting it into a format that can be analyzed, and loading it into a data warehouse or system for use in reporting and analytics.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by explaining how ETL helps in preparing data for analysis, providing a clear and concise description of the process.'}),\n",
       " ({'id': 151,\n",
       "   'question': \"How can you ensure a model's performance is not overly dependent on the training data?\"},\n",
       "  'To prevent overfitting involves techniques like cross-validation, regularization, and model complexity control.',\n",
       "  {'Relevance': 'PARTLY_RELEVANT',\n",
       "   'Explanation': \"The generated answer is related to model performance, but it does not directly address how to ensure a model's performance is not overly dependent on the training data. It mentions techniques to prevent overfitting, which is a part of the problem, but not the whole solution.\"}),\n",
       " ({'id': 166,\n",
       "   'question': 'How does AdaGrad scale parameters according to past gradients?'},\n",
       "  'AdaGrad scales parameters according to past gradients by adjusting the learning rates for each parameter individually based on the accumulation of past gradients.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses how AdaGrad scales parameters according to past gradients, providing a clear and specific explanation that matches the question.'}),\n",
       " ({'id': 5,\n",
       "   'question': 'What options are available in XGBoost to utilize GPUs for faster training?'},\n",
       "  \"'tree_method = 'gpu_hist''.\",\n",
       "  {'Relevance': 'PARTLY_RELEVANT',\n",
       "   'Explanation': \"The generated answer is partially relevant as it mentions 'gpu_hist' which is related to GPU utilization, but it does not provide a comprehensive list of options available in XGBoost for faster training.\"}),\n",
       " ({'id': 171,\n",
       "   'question': 'What is the primary goal of recommendation algorithms?'},\n",
       "  'Recommendation algorithms analyze past user preferences and interactions to generate personalized suggestions or recommendations for items or content.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the primary goal of recommendation algorithms, which is to generate personalized suggestions based on user preferences and interactions.'}),\n",
       " ({'id': 90,\n",
       "   'question': 'How does unsupervised learning handle unlabeled data?'},\n",
       "  'Unsupervised learning handles unlabeled data by identifying patterns or structures within it without explicit labels or target outputs.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by explaining how unsupervised learning handles unlabeled data, making it highly relevant to the query.'}),\n",
       " ({'id': 120,\n",
       "   'question': 'How does a model determine the category of a new observation?'},\n",
       "  'The model determines the category of a new observation by classifying it into one of the pre-defined categories based on the training dataset.',\n",
       "  {'Relevance': 'PARTLY_RELEVANT',\n",
       "   'Explanation': 'The generated answer is related to classification, but it does not specifically address how a model determines the category of a new observation in the context of machine learning or data analysis.'}),\n",
       " ({'id': 97,\n",
       "   'question': 'In search functions, what technique is used to identify non-identical strings?'},\n",
       "  'Flexible string matching.',\n",
       "  {'Relevance': 'PARTLY_RELEVANT',\n",
       "   'Explanation': \"The generated answer mentions 'Flexible string matching', which is related to search functions, but it does not explicitly mention identifying non-identical strings.\"}),\n",
       " ({'id': 162,\n",
       "   'question': 'What types of statistical biases can lead to incorrect conclusions?'},\n",
       "  'Sampling bias, confirmation bias, survivorship bias, selection bias.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the types of statistical biases that can lead to incorrect conclusions, which is exactly what the question asks for.'}),\n",
       " ({'id': 144, 'question': 'What is PCA used for in data analysis?'},\n",
       "  'PCA is used for dimensionality reduction, simplifying complex datasets, facilitating visualization, and enabling efficient data analysis and interpretation.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': \"The generated answer directly addresses the question about PCA's use in data analysis, providing relevant information on its applications.\"}),\n",
       " ({'id': 16,\n",
       "   'question': 'What aggregate functions can be applied to each group using groupby?'},\n",
       "  'mean, median, min, max, sum, count, std, var, skew, kurt, sem, iqr, quantile, prod, size, unique, nunique, describe, info, head, tail, index, columns, dtypes, shape, values, isnull, notnull, isna, notna.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer lists various aggregate functions that can be applied to each group using groupby, which directly addresses the question.'}),\n",
       " ({'id': 75,\n",
       "   'question': 'Which natural language processing library is written in Java?'},\n",
       "  'OpenNLP.',\n",
       "  {'Relevance': 'PARTLY_RELEVANT',\n",
       "   'Explanation': \"The generated answer, OpenNLP, is related to natural language processing but it's not a library written in Java as the question asks for.\"}),\n",
       " ({'id': 62,\n",
       "   'question': 'Can you describe the process of building a tree-based model?'},\n",
       "  'Initialize tree While stopping criterion not met: Find best split Add node to tree Fit data to node Repeat until stopping criterion met Return tree',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly describes the process of building a tree-based model, matching the context and content of the question.'}),\n",
       " ({'id': 144, 'question': 'How does PCA simplify complex datasets?'},\n",
       "  'PCA simplifies complex datasets by reducing dimensionality through linear combinations of original variables.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses how PCA simplifies complex datasets, matching the context of the question.'}),\n",
       " ({'id': 103,\n",
       "   'question': 'What is the main goal of the Probably Approximately Correct (PAC) learning framework?'},\n",
       "  'The main goal of the Probably Approximately Correct (PAC) learning framework is to understand the efficiency of machine learning algorithms in terms of their ability to provide guarantees on the performance of learned functions from limited samples.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the main goal of the PAC learning framework, providing a clear and concise description that matches the context of the question.'}),\n",
       " ({'id': 41,\n",
       "   'question': 'What statistical methods are used in linear regression?'},\n",
       "  'OLS minimizes the distance between actual and predicted values.',\n",
       "  {'Relevance': 'PARTLY_RELEVANT',\n",
       "   'Explanation': 'The generated answer is related to linear regression, but it only mentions OLS and does not provide a comprehensive list of statistical methods used in linear regression.'}),\n",
       " ({'id': 84,\n",
       "   'question': 'How does stratified sampling ensure proportional representation of various subgroups?'},\n",
       "  'By drawing random samples from each stratum, stratified sampling ensures proportional representation of various subgroups.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': \"The generated answer directly addresses the question's concern about stratified sampling and its effect on subgroup representation, providing a clear explanation of how it ensures proportional representation.\"}),\n",
       " ({'id': 38,\n",
       "   'question': 'What are the primary differences between collaborative filtering and content-based filtering?'},\n",
       "  'Collaborative filtering analyzes user behavior similarity, while content-based filtering evaluates item properties to make suggestions.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the primary differences between collaborative filtering and content-based filtering, matching the context of the question.'}),\n",
       " ({'id': 98,\n",
       "   'question': 'What is the primary goal of adjusting weights and biases based on computed gradients?'},\n",
       "  'Adjusting weights and biases based on computed gradients moves towards the minimum loss point.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': \"The generated answer directly addresses the question's topic of adjusting weights and biases, providing a clear explanation related to the concept of minimizing loss.\"}),\n",
       " ({'id': 22, 'question': 'Why is the IQR useful in statistical analysis?'},\n",
       "  'The IQR provides insights into the variability of values within a dataset, focusing on the central interval containing half of the sample. It is robust against outliers and extreme values, making it a useful measure of data spread in statistical analysis and inference.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': \"The generated answer directly addresses the question's inquiry about the usefulness of IQR in statistical analysis, providing a clear explanation of its benefits and applications.\"}),\n",
       " ({'id': 160,\n",
       "   'question': 'What is the purpose of a classification threshold in logistic regression?'},\n",
       "  'The classification threshold is a cutoff point used in logistic regression and other probabilistic classifiers to distinguish between different class labels based on predicted probabilities.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the purpose of a classification threshold in logistic regression, matching the context and content of the question.'}),\n",
       " ({'id': 192,\n",
       "   'question': 'What is the primary goal of managing model complexity in machine learning?'},\n",
       "  'The primary goal of managing model complexity in machine learning is to prevent underfitting or overfitting by achieving an optimal balance between bias and variance.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by explaining the primary goal of managing model complexity in machine learning, which is to prevent underfitting or overfitting.'}),\n",
       " ({'id': 150,\n",
       "   'question': 'What is the threshold for an effect to be considered statistically significant?'},\n",
       "  '0.05.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer (0.05) directly corresponds to the threshold value commonly used in statistical significance tests, making it highly relevant to the question.'}),\n",
       " ({'id': 112,\n",
       "   'question': 'What are the common pitfalls that can skew results when collecting data?'},\n",
       "  'Sampling biases include selection bias, undercoverage bias, and survivorship bias.',\n",
       "  {'Relevance': 'PARTLY_RELEVANT',\n",
       "   'Explanation': 'The generated answer is related to data collection, but it specifically addresses sampling biases, which is a subset of potential pitfalls that can skew results when collecting data.'}),\n",
       " ({'id': 70,\n",
       "   'question': 'What tools enable data engineers to process, analyze, and prepare data efficiently?'},\n",
       "  'NumPy, pandas, and scipy enable efficient data processing, statistical analysis, and data preparation tasks.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by listing specific tools that enable data engineers to process, analyze, and prepare data efficiently.'}),\n",
       " ({'id': 140,\n",
       "   'question': 'In what scenarios would you use the % operator to compute remainders in Python?'},\n",
       "  'You would use the % operator to compute remainders in Python when performing division operations where the quotient is not needed but the remainder is.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by specifying scenarios where the % operator is used to compute remainders in Python, matching the context of the question.'}),\n",
       " ({'id': 45,\n",
       "   'question': 'What is an autonomous entity in AI that perceives surroundings through sensors?'},\n",
       "  'An autonomous entity in AI that perceives surroundings through sensors is an agent.',\n",
       "  {'Relevance': 'PARTLY_RELEVANT',\n",
       "   'Explanation': \"The generated answer is partially relevant because it mentions an autonomous entity in AI, which aligns with the question's context. However, it does not explicitly mention perception through sensors, making it only partly relevant.\"}),\n",
       " ({'id': 17,\n",
       "   'question': 'How do wrapper methods iteratively add or remove features based on model performance?'},\n",
       "  'Wrapper methods iteratively add or remove features based on model performance.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly answers the question by providing a clear and concise description of how wrapper methods iteratively add or remove features based on model performance.'}),\n",
       " ({'id': 106,\n",
       "   'question': 'What ensemble learning method uses numerous decision trees to reduce overfitting?'},\n",
       "  'Random forests.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': \"The generated answer, 'Random forests', directly addresses the ensemble learning method mentioned in the question, indicating a high level of relevance.\"}),\n",
       " ({'id': 86,\n",
       "   'question': 'What advanced methods can be employed for complex pattern recognition in sequential data?'},\n",
       "  'Autoencoders, Generative Adversarial Networks (GANs), and Recurrent Neural Networks (RNNs) can be employed for complex pattern recognition in sequential data.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by listing specific methods (Autoencoders, GANs, and RNNs) that can be employed for complex pattern recognition in sequential data.'}),\n",
       " ({'id': 153, 'question': 'What environments enable AI model development?'},\n",
       "  'Environments for developing AI models include libraries like Scikit Learn for machine learning to TensorFlow and Keras for deep learning.',\n",
       "  {'Relevance': 'PARTLY_RELEVANT',\n",
       "   'Explanation': 'The generated answer is partially relevant because it mentions environments for developing AI models, but it only focuses on machine learning and deep learning libraries, ignoring other possible environments that might be relevant to the question.'}),\n",
       " ({'id': 20,\n",
       "   'question': 'How does a basic neural network learn patterns from data?'},\n",
       "  'A basic neural network learns patterns from data by processing inputs through interconnected layers of nodes and outputting a result based on the learned patterns in the data.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by explaining how a basic neural network learns patterns from data, matching the context and content of the question.'}),\n",
       " ({'id': 142, 'question': 'What is the Bag of Words model used for?'},\n",
       "  'The Bag of Words model simplifies text by treating it as a collection of independent items, allowing for straightforward but effective text categorization and information retrieval based on word frequencies.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question about the purpose of the Bag of Words model, providing a clear and concise explanation.'}),\n",
       " ({'id': 145, 'question': 'How does DeepFace classify faces accurately?'},\n",
       "  'Employing neural networks to detect, align, extract patterns, and classify faces accurately, leveraging large training datasets for robust performance.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses how DeepFace classifies faces accurately, mentioning specific techniques and leveraging large training datasets.'}),\n",
       " ({'id': 55,\n",
       "   'question': 'What method is used during model training to selectively calculate probabilities for all positive class instances and a random subset of negative ones?'},\n",
       "  'Candidate sampling.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': \"The generated answer, 'Candidate sampling', directly corresponds to the method used during model training to selectively calculate probabilities for all positive class instances and a random subset of negative ones, as described in the question.\"}),\n",
       " ({'id': 14,\n",
       "   'question': 'Which statistical models are robust against anomalies in time series data?'},\n",
       "  'Robust regression or robust time series models.',\n",
       "  {'Relevance': 'PARTLY_RELEVANT',\n",
       "   'Explanation': 'The generated answer mentions robust time series models, which is related to the question about statistical models robust against anomalies in time series data. However, it does not provide a comprehensive list of relevant models, making it only partly relevant.'}),\n",
       " ({'id': 185,\n",
       "   'question': 'How do knowledge engineers capture human expertise?'},\n",
       "  'Knowledge engineers capture human expertise by eliciting, representing, and formalizing knowledge from human experts into a computable form that machines can utilize for problem-solving, decision-making, and reasoning tasks.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by describing how knowledge engineers capture human expertise, providing a clear and relevant explanation.'}),\n",
       " ({'id': 180,\n",
       "   'question': 'In what ways can virtual assistants benefit from NLP capabilities?'},\n",
       "  'Speech recognition, powering virtual assistants to understand and respond to spoken commands, enhancing user experience.',\n",
       "  {'Relevance': 'PARTLY_RELEVANT',\n",
       "   'Explanation': 'The generated answer partially addresses the question by mentioning one way virtual assistants can benefit from NLP capabilities, but it does not provide a comprehensive list of ways as implied by the question.'}),\n",
       " ({'id': 197,\n",
       "   'question': 'What search strategy involves running two simultaneous searches?'},\n",
       "  'A bidirectional search algorithm runs two simultaneous searches: one forward from the starting point and one backward from the goal.',\n",
       "  {'Relevance': 'PARTLY_RELEVANT',\n",
       "   'Explanation': 'The generated answer is related to search strategies, but it specifically talks about bidirectional search algorithms, which is not directly answering the question about a general search strategy involving two simultaneous searches.'}),\n",
       " ({'id': 182,\n",
       "   'question': 'In what way do distributed systems like Hadoop benefit from organizing data storage efficiently?'},\n",
       "  'Distributed systems like Hadoop benefit from organizing data storage efficiently by optimizing network traffic and data reliability across multiple racks.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': \"The generated answer directly addresses the question's focus on efficient data storage in distributed systems like Hadoop, providing a relevant explanation of its benefits.\"}),\n",
       " ({'id': 46,\n",
       "   'question': \"What statistical methods are used to determine if a sample's characteristics can be generalized to the entire population?\"},\n",
       "  \"Hypothesis testing evaluates whether there's sufficient evidence in a sample of data to infer that a certain condition holds for the entire population. Statistical tests like the T-test, Chi-Square, and ANOVA assess the validity of assumptions related to means, variances, and distributions.\",\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by describing statistical methods used to infer population characteristics, specifically mentioning hypothesis testing and related statistical tests.'}),\n",
       " ({'id': 21,\n",
       "   'question': 'What transformation does softmax apply to neural network outputs?'},\n",
       "  'Softmax transforms neural network outputs into probability distributions over classes.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the transformation applied by softmax to neural network outputs, matching the context of the question.'}),\n",
       " ({'id': 132,\n",
       "   'question': 'List three examples of applications where weak AI can be effectively used.'},\n",
       "  'Virtual assistants, recommendation systems, image recognition.',\n",
       "  {'Relevance': 'PARTLY_RELEVANT',\n",
       "   'Explanation': 'The generated answer partially addresses the question by listing some examples of applications where weak AI can be used, but it does not fully cover the scope of the question as it only provides three specific examples and does not provide a comprehensive list.'}),\n",
       " ({'id': 166,\n",
       "   'question': 'What algorithm adjusts learning rates for each parameter individually?'},\n",
       "  'AdaGrad.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': \"The generated answer, AdaGrad, is directly related to adjusting learning rates for each parameter individually, which matches the question's context.\"}),\n",
       " ({'id': 168,\n",
       "   'question': 'What parameter is used to determine the number of trees in a random forest?'},\n",
       "  'The n_estimators parameter.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by specifying the parameter used to determine the number of trees in a random forest.'}),\n",
       " ({'id': 31, 'question': 'What patterns can models identify in data?'},\n",
       "  'Models can identify patterns such as decision boundaries between classes, relationships in data, predictive modeling, and hidden relationships.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by listing specific patterns that models can identify in data, making it highly relevant to the query.'}),\n",
       " ({'id': 78,\n",
       "   'question': 'What role do data mining and data warehousing play in enabling informed decision-making?'},\n",
       "  'Data mining uncovers patterns and relationships in data, whereas data warehousing integrates and stores data for analysis purposes. Both play complementary roles in extracting value from data, enabling informed decision-making and strategic planning in organizations.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the role of data mining and data warehousing in enabling informed decision-making, providing a clear explanation of their complementary roles.'}),\n",
       " ({'id': 66,\n",
       "   'question': 'What is the purpose of using conditional formatting in a dataset?'},\n",
       "  'Highlight or differentiate data points in a dataset, aiding in the quick identification of trends, anomalies, or specific conditions.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the purpose of using conditional formatting in a dataset, matching the context and content of the question.'}),\n",
       " ({'id': 198,\n",
       "   'question': 'Can gradient descent methods converge to the same point under varying cost functions?'},\n",
       "  'Gradient descent methods may converge to different local optima, which depend on the starting conditions and the nature of the cost function.',\n",
       "  {'Relevance': 'PARTLY_RELEVANT',\n",
       "   'Explanation': 'The generated answer partially addresses the question by mentioning that gradient descent methods may converge to different local optima, but it does not directly address the convergence under varying cost functions.'}),\n",
       " ({'id': 6,\n",
       "   'question': 'What can be reused in different programs when using a Python module?'},\n",
       "  'A Python module can be reused in different programs.',\n",
       "  {'Relevance': 'PARTLY_RELEVANT',\n",
       "   'Explanation': \"The generated answer partially addresses the question, but it's more of a statement about reusability rather than providing specific information about what can be reused.\"}),\n",
       " ({'id': 135,\n",
       "   'question': 'What are the three main loop control statements in programming?'},\n",
       "  'Not enough context in questions and answers database.',\n",
       "  {'Relevance': 'NON_RELEVANT',\n",
       "   'Explanation': 'The generated answer does not address the question about loop control statements in programming, instead stating that there is a lack of context in the database.'}),\n",
       " ({'id': 187,\n",
       "   'question': 'What statistical properties must variables have for linear regression to hold?'},\n",
       "  'Linear relationships, constant variance (homoscedasticity), no multicollinearity, and normal distribution of errors.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the statistical properties required for linear regression to hold, as specified in the question.'}),\n",
       " ({'id': 104,\n",
       "   'question': 'What is the typical deviation of data values from their mean, as expressed by standard deviation?'},\n",
       "  'Standard deviation measures the spread or variability of data points around the mean of a distribution. It quantifies the average distance of individual data points from the mean, providing insights into the dispersion of data. By taking the square root of the variance, standard deviation expresses the typical deviation of data values from the mean, offering a concise summary of data variability and aiding in statistical analysis and decision-making processes.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by explaining what standard deviation measures and its relation to data values from their mean.'}),\n",
       " ({'id': 136,\n",
       "   'question': \"How do rotations affect a CNN's performance on images?\"},\n",
       "  \"Inherently lack rotation invariance, meaning a model's predictions can be affected if the input image is rotated unless the dataset has been augmented with rotated examples during training.\",\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': \"The generated answer directly addresses the question's topic, discussing how rotations affect CNNs' performance on images.\"}),\n",
       " ({'id': 173,\n",
       "   'question': 'What ensures interpretability of machine learning models when dealing with categorical data?'},\n",
       "  'One-hot encoding.',\n",
       "  {'Relevance': 'PARTLY_RELEVANT',\n",
       "   'Explanation': \"The generated answer is related to machine learning models, but it only addresses one aspect of interpretability (encoding categorical data), and does not provide a comprehensive solution for the question's requirement.\"}),\n",
       " ({'id': 31,\n",
       "   'question': \"What tasks are facilitated by exploring data's inherent structure?\"},\n",
       "  \"Unsupervised learning involves training models to identify patterns or structures within data without explicit labels or target outputs. By exploring data's inherent structure, unsupervised learning algorithms reveal hidden insights and groupings, facilitating tasks like clustering, dimensionality reduction, and anomaly detection.\",\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': \"The generated answer directly addresses the question by explaining how exploring data's inherent structure facilitates tasks like clustering, dimensionality reduction, and anomaly detection, which are all related to unsupervised learning.\"}),\n",
       " ({'id': 98,\n",
       "   'question': 'How do gradients influence adjustments to weights and biases in a model?'},\n",
       "  'The gradients influence adjustments to weights and biases in a model by indicating the direction and magnitude of change needed to minimize loss.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by explaining how gradients influence adjustments to weights and biases in a model, providing a clear and concise explanation.'}),\n",
       " ({'id': 156, 'question': 'What does the survival function represent?'},\n",
       "  'The survival function represents the probability that a subject will survive beyond a given time point.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly answers the question about what the survival function represents, providing a clear and concise definition.'}),\n",
       " ({'id': 10,\n",
       "   'question': 'What visual tool provides insights into data concentration and frequency?'},\n",
       "  'A histogram is a graphical representation depicting the distribution of numerical data through vertical bars, providing visual insights into data concentration and frequency within specified intervals or bins.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by describing a histogram as a tool that provides insights into data concentration and frequency, matching the context of the question.'}),\n",
       " ({'id': 125,\n",
       "   'question': 'Which search strategies can be employed to optimize hyperparameters?'},\n",
       "  'Grid Search, Random Search, and Bayesian Optimization can be employed to optimize hyperparameters.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by listing specific search strategies that can be employed to optimize hyperparameters.'}),\n",
       " ({'id': 29, 'question': 'How do NLP systems process text and speech data?'},\n",
       "  'NLP systems process text and speech data by extracting meaning, recognizing patterns, and facilitating communication between humans and machines.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by describing how NLP systems process text and speech data, making it highly relevant.'}),\n",
       " ({'id': 195,\n",
       "   'question': 'What is a reference point for comparing model performance?'},\n",
       "  'A baseline in machine learning establishes a reference point against which the performance of more complex models can be compared.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by providing an example of a reference point in machine learning, which is relevant to comparing model performance.'}),\n",
       " ({'id': 148,\n",
       "   'question': 'How does data mining differ from data profiling in terms of analysis goals?'},\n",
       "  'Data mining uncovers patterns and relations in data, enabling predictive modeling and decision-making, whereas data profiling examines individual data attributes, providing insights into data characteristics.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': \"The generated answer directly addresses the question's inquiry into the difference between data mining and data profiling in terms of analysis goals, providing a clear distinction between the two concepts.\"}),\n",
       " ({'id': 83,\n",
       "   'question': 'How does the input layer process raw data in a neural network?'},\n",
       "  'The input layer processes raw data in a neural network by receiving and transmitting input signals to subsequent layers for further processing and analysis.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses how the input layer processes raw data in a neural network, providing a clear and concise explanation that matches the context of the question.'}),\n",
       " ({'id': 58,\n",
       "   'question': 'What impact does variance have on statistical analyses and decision-making?'},\n",
       "  'Variance has a significant impact on statistical analyses and decision-making by quantifying the spread or dispersion of data points around the mean, influencing fields such as finance, engineering, and quality control.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the impact of variance on statistical analyses and decision-making, matching the context of the question.'}),\n",
       " ({'id': 167,\n",
       "   'question': \"How do Amazon's product recommendations work without needing to know the features of items themselves?\"},\n",
       "  'The recommendations on Amazon are generated through a collaborative filtering algorithm, which relies on user behavior such as transaction history and ratings to suggest items to new users without needing to know the features of the items themselves.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': \"The generated answer directly addresses the question by explaining how Amazon's product recommendations work without needing to know the features of items themselves, using a specific algorithm and user behavior as examples.\"}),\n",
       " ({'id': 198,\n",
       "   'question': 'What happens when gradient descent methods are applied with different initial conditions?'},\n",
       "  'Gradient descent methods may converge to different local optima, which depend on the starting conditions and the nature of the cost function.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question about the effect of different initial conditions on gradient descent methods, providing a relevant and accurate response.'}),\n",
       " ({'id': 155, 'question': 'What is TensorFlow, a machine learning framework?'},\n",
       "  'A versatile and scalable machine learning framework designed for building and deploying AI models across various domains. Developed by Google Brain, TensorFlow offers comprehensive support for deep learning, reinforcement learning, and distributed computing.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly answers the question about TensorFlow, providing its description and features.'}),\n",
       " ({'id': 187,\n",
       "   'question': 'Under what conditions does linear regression assume errors are distributed?'},\n",
       "  'Errors are distributed normally under the assumption of linear regression.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by specifying the distribution of errors in linear regression, which is exactly what the question asks for.'}),\n",
       " ({'id': 30,\n",
       "   'question': 'Describe the format in which datasets are typically stored.'},\n",
       "  'CSV, JSON, and Parquet are common formats used to store datasets.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by listing common formats used to store datasets, which is exactly what the question asks for.'}),\n",
       " ({'id': 96,\n",
       "   'question': 'What tangible outcomes are expected from a project?'},\n",
       "  \"Project deliverables are the tangible or intangible outcomes of a project that fulfill the project's objectives and are handed over to the client or stakeholder upon completion.\",\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by defining project deliverables as tangible outcomes of a project, which is in line with the expected outcome mentioned in the question.'}),\n",
       " ({'id': 87,\n",
       "   'question': 'How does RMSE measure the dispersion or variability of data points around a regression line?'},\n",
       "  'RMSE measures the dispersion or variability of data points around a regression line by quantifying the average deviation between observed and predicted values.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by explaining how RMSE measures dispersion around a regression line, matching the context and content of the question.'}),\n",
       " ({'id': 58,\n",
       "   'question': 'How is variance related to data points around the mean?'},\n",
       "  'Variance quantifies the spread or dispersion of data points around the mean, reflecting the magnitude of differences among individual values.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': \"The generated answer directly addresses the question's topic, explaining how variance relates to data points around the mean.\"}),\n",
       " ({'id': 196,\n",
       "   'question': 'What enables neural networks to learn complex relationships between inputs and outputs?'},\n",
       "  'Activation functions introduce nonlinearity, enabling neural networks to learn complex relationships between inputs and outputs.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by explaining how activation functions enable neural networks to learn complex relationships, which is exactly what the question asks.'}),\n",
       " ({'id': 80,\n",
       "   'question': 'What Python libraries are commonly used for data manipulation?'},\n",
       "  'NumPy, Pandas, Scikit-Learn.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by listing specific Python libraries commonly used for data manipulation.'}),\n",
       " ({'id': 190,\n",
       "   'question': 'What is the primary purpose of incorporating covariates into an analysis using ANCOVA?'},\n",
       "  'ANCOVA allows researchers to investigate how categorical variables impact continuous outcomes while accounting for the influence of covariates.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the primary purpose of incorporating covariates into an analysis using ANCOVA, making it highly relevant to the question.'}),\n",
       " ({'id': 54,\n",
       "   'question': 'How can selecting non-representative participants affect the validity of study conclusions?'},\n",
       "  'Selection bias can lead to skewed results and affect the validity of study conclusions.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by explaining how selecting non-representative participants can affect the validity of study conclusions, making it highly relevant to the original question.'}),\n",
       " ({'id': 2,\n",
       "   'question': \"What are the implications of a test result that incorrectly suggests a condition's presence?\"},\n",
       "  \"A false positive incorrectly indicates a condition is present when it's not.\",\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the implications of an incorrect test result, matching the context and content of the question.'}),\n",
       " ({'id': 147,\n",
       "   'question': 'How do generalized linear models differ from traditional linear regression?'},\n",
       "  'Generalized linear models differ from traditional linear regression by allowing for response variables with error distribution models other than a normal distribution.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the difference between generalized linear models and traditional linear regression, providing a clear and concise explanation.'}),\n",
       " ({'id': 4, 'question': 'What is semi-supervised learning?'},\n",
       "  'Semi-supervised learning integrates both labeled and unlabeled data during model training, leveraging the abundance of unlabeled data alongside limited labeled data to enhance model performance and generalization.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question about semi-supervised learning, providing a clear and concise definition.'}),\n",
       " ({'id': 64, 'question': 'What factors influence chart creation?'},\n",
       "  'The factors influencing chart creation are the data type, the relationships to be illustrated, the variables involved, and the interactivity required by the end-user.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the factors influencing chart creation, which is the main topic of the question.'}),\n",
       " ({'id': 125,\n",
       "   'question': 'List different methods to find optimal hyperparameters for a model.'},\n",
       "  'Grid Search, Random Search, Bayesian Optimization, Grid Search exhaustively explores parameter combinations, Random Search randomly samples from a predefined space, and Bayesian Optimization uses Bayesian inference to direct the search efficiently.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses the question by listing different methods to find optimal hyperparameters for a model, providing a clear and concise explanation of each method.'}),\n",
       " ({'id': 173,\n",
       "   'question': 'How are categories represented in one-hot encoding?'},\n",
       "  'Each category is represented by a binary vector where only one bit is \"hot\" (set to 1) for each category, indicating its presence.',\n",
       "  {'Relevance': 'RELEVANT',\n",
       "   'Explanation': 'The generated answer directly addresses how categories are represented in one-hot encoding, matching the context of the question.'})]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cf61170e-bfde-4889-8cd3-98fbfcc89918",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3e598eb6-4272-442b-aa98-3c169ecb9f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tokenization, parsing, named entity recognition.</td>\n",
       "      <td>149</td>\n",
       "      <td>List common NLP tasks supported by Apache Open...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Break exits loop prematurely.</td>\n",
       "      <td>135</td>\n",
       "      <td>What happens when you use the break statement ...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patterns and relationships are discovered with...</td>\n",
       "      <td>170</td>\n",
       "      <td>Can you describe a scenario where patterns and...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The generated answer partially addresses the q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The S-curve serves as a visual tool for analyz...</td>\n",
       "      <td>152</td>\n",
       "      <td>How is an S-curve used for trend analysis and ...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A confidence interval is a range of values tha...</td>\n",
       "      <td>68</td>\n",
       "      <td>What is a range of values that likely contains...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Generalized linear models differ from traditio...</td>\n",
       "      <td>147</td>\n",
       "      <td>How do generalized linear models differ from t...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Semi-supervised learning integrates both label...</td>\n",
       "      <td>4</td>\n",
       "      <td>What is semi-supervised learning?</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>The factors influencing chart creation are the...</td>\n",
       "      <td>64</td>\n",
       "      <td>What factors influence chart creation?</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Grid Search, Random Search, Bayesian Optimizat...</td>\n",
       "      <td>125</td>\n",
       "      <td>List different methods to find optimal hyperpa...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Each category is represented by a binary vecto...</td>\n",
       "      <td>173</td>\n",
       "      <td>How are categories represented in one-hot enco...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses how ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               answer   id  \\\n",
       "0    Tokenization, parsing, named entity recognition.  149   \n",
       "1                       Break exits loop prematurely.  135   \n",
       "2   Patterns and relationships are discovered with...  170   \n",
       "3   The S-curve serves as a visual tool for analyz...  152   \n",
       "4   A confidence interval is a range of values tha...   68   \n",
       "..                                                ...  ...   \n",
       "95  Generalized linear models differ from traditio...  147   \n",
       "96  Semi-supervised learning integrates both label...    4   \n",
       "97  The factors influencing chart creation are the...   64   \n",
       "98  Grid Search, Random Search, Bayesian Optimizat...  125   \n",
       "99  Each category is represented by a binary vecto...  173   \n",
       "\n",
       "                                             question        relevance  \\\n",
       "0   List common NLP tasks supported by Apache Open...         RELEVANT   \n",
       "1   What happens when you use the break statement ...         RELEVANT   \n",
       "2   Can you describe a scenario where patterns and...  PARTLY_RELEVANT   \n",
       "3   How is an S-curve used for trend analysis and ...         RELEVANT   \n",
       "4   What is a range of values that likely contains...         RELEVANT   \n",
       "..                                                ...              ...   \n",
       "95  How do generalized linear models differ from t...         RELEVANT   \n",
       "96                  What is semi-supervised learning?         RELEVANT   \n",
       "97             What factors influence chart creation?         RELEVANT   \n",
       "98  List different methods to find optimal hyperpa...         RELEVANT   \n",
       "99  How are categories represented in one-hot enco...         RELEVANT   \n",
       "\n",
       "                                          explanation  \n",
       "0   The generated answer directly addresses the qu...  \n",
       "1   The generated answer directly addresses the qu...  \n",
       "2   The generated answer partially addresses the q...  \n",
       "3   The generated answer directly addresses the us...  \n",
       "4   The generated answer directly addresses the qu...  \n",
       "..                                                ...  \n",
       "95  The generated answer directly addresses the di...  \n",
       "96  The generated answer directly addresses the qu...  \n",
       "97  The generated answer directly addresses the fa...  \n",
       "98  The generated answer directly addresses the qu...  \n",
       "99  The generated answer directly addresses how ca...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ac52a63d-6d96-4116-a3d3-b906d52c2afd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.79\n",
       "PARTLY_RELEVANT    0.20\n",
       "NON_RELEVANT       0.01\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a5c09657-6136-4523-ac3d-d7dcd3cb626f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'llama3.1:8b'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3b1acbc2-9690-4d51-98a6-b81ee659ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_eval.to_csv('../data/rag-eval-{gpt-4o-mini}.csv', index=False)\n",
    "df_eval.to_csv(f'../data/rag-eval-{model}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9492ff9c-d633-4d02-a573-217e3978ccbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Not enough context in questions and answers da...</td>\n",
       "      <td>135</td>\n",
       "      <td>What are the three main loop control statement...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the ques...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               answer   id  \\\n",
       "67  Not enough context in questions and answers da...  135   \n",
       "\n",
       "                                             question     relevance  \\\n",
       "67  What are the three main loop control statement...  NON_RELEVANT   \n",
       "\n",
       "                                          explanation  \n",
       "67  The generated answer does not address the ques...  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval[df_eval.relevance == 'NON_RELEVANT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9c14116b-bf84-4d61-997b-44724d3b6721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before we did evaluation with llama3.1:8b, below with gpt-4o-mini\n",
    "#as we have already the answers from the first model we take those answers from the dataframe instead of repeating\n",
    "#all the calls to llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "74777637-711e-4fdb-ac58-70043a8a27ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=OpenAI()\n",
    "model_2='gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e71c6a46-e19c-4f87-9ea5-d848db367b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    tokens = {\n",
    "            'prompt_tokens': response.usage.prompt_tokens,\n",
    "            'completion_tokens': response.usage.completion_tokens,\n",
    "            'total_tokens': response.usage.total_tokens\n",
    "        }\n",
    "    \n",
    "    return response.choices[0].message.content, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b7d9acf4-3a73-44a6-9b61-b064c2e72e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:47<00:00,  1.68s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Lists to hold evaluation results and token counts for each type of token\n",
    "evaluations = []\n",
    "prompt_tokens_list = []\n",
    "completion_tokens_list = []\n",
    "total_tokens_list = []\n",
    "\n",
    "# Assuming df_eval is your DataFrame with the relevant structure\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "\n",
    "    # Lookup the answer in df_eval based on the question\n",
    "    answer_row = df_eval[df_eval['question'] == question]\n",
    "\n",
    "    if not answer_row.empty:\n",
    "        answer_llm = answer_row['answer'].values[0]  # Get the answer from the DataFrame\n",
    "    else:\n",
    "        answer_llm = \"No answer found\"  # Handle case where question is not in DataFrame\n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    # Control of tokens used for the query to see cost of API calls\n",
    "    evaluation, tokens = llm(prompt, model_2)  # Get evaluation and token usage\n",
    "\n",
    "    # Call the parsing function robust_json_loads\n",
    "    success, evaluation, error_message = robust_json_loads(evaluation)\n",
    "\n",
    "    # Append the evaluation\n",
    "    evaluations.append((record, answer_llm, evaluation))\n",
    "\n",
    "    # Unpack tokens into separate lists\n",
    "    prompt_tokens_list.append(tokens['prompt_tokens'])\n",
    "    completion_tokens_list.append(tokens['completion_tokens'])\n",
    "    total_tokens_list.append(tokens['total_tokens'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "32bee217-326e-4048-ae19-ecba5bc92232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for tokens only\n",
    "df_tokens = pd.DataFrame({\n",
    "    'prompt_tokens': prompt_tokens_list,\n",
    "    'completion_tokens': completion_tokens_list,\n",
    "    'total_tokens': total_tokens_list\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "56925bf9-5784-4286-a560-c50a388db00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201</td>\n",
       "      <td>60</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198</td>\n",
       "      <td>47</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>236</td>\n",
       "      <td>59</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>217</td>\n",
       "      <td>71</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220</td>\n",
       "      <td>43</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>216</td>\n",
       "      <td>46</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>222</td>\n",
       "      <td>49</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>217</td>\n",
       "      <td>55</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>231</td>\n",
       "      <td>56</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>220</td>\n",
       "      <td>57</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    prompt_tokens  completion_tokens  total_tokens\n",
       "0             201                 60           261\n",
       "1             198                 47           245\n",
       "2             236                 59           295\n",
       "3             217                 71           288\n",
       "4             220                 43           263\n",
       "..            ...                ...           ...\n",
       "95            216                 46           262\n",
       "96            222                 49           271\n",
       "97            217                 55           272\n",
       "98            231                 56           287\n",
       "99            220                 57           277\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "72cef8c4-5720-4086-8717-978546a7f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation of costs\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_token_costs(df_tokens, price_per_input, price_per_output):\n",
    "    \"\"\"\n",
    "    Calculate total costs based on token usage.\n",
    "\n",
    "    Parameters:\n",
    "    - df_tokens: DataFrame containing token counts with columns 'prompt_tokens' and 'completion_tokens'.\n",
    "    - price_per_input: Cost per 1 million input tokens (prompt tokens).\n",
    "    - price_per_output: Cost per 1 million output tokens (completion tokens).\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame summarizing costs per token type and the total cost.\n",
    "    \"\"\"\n",
    "    # Calculate costs for input tokens\n",
    "    df_tokens['input_cost'] = (df_tokens['prompt_tokens'] / 1_000_000) * price_per_input\n",
    "    \n",
    "    # Calculate costs for output tokens\n",
    "    df_tokens['output_cost'] = (df_tokens['completion_tokens'] / 1_000_000) * price_per_output\n",
    "    \n",
    "    # Calculate total cost\n",
    "    df_tokens['total_cost'] = df_tokens['input_cost'] + df_tokens['output_cost']\n",
    "    \n",
    "    # Summarize costs\n",
    "    total_input_cost = df_tokens['input_cost'].sum()\n",
    "    total_output_cost = df_tokens['output_cost'].sum()\n",
    "    total_cost = df_tokens['total_cost'].sum()\n",
    "\n",
    "    # Create a summary DataFrame\n",
    "    cost_summary = pd.DataFrame({\n",
    "        'Total Input Cost': [total_input_cost],\n",
    "        'Total Output Cost': [total_output_cost],\n",
    "        'Total Cost': [total_cost]\n",
    "    })\n",
    "\n",
    "    return df_tokens, cost_summary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "542516fd-4f86-4e5b-ba05-2bbbeba9250d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens with Costs:\n",
      "    prompt_tokens  completion_tokens  total_tokens  input_cost  output_cost  \\\n",
      "0             201                 60           261    0.000030     0.000036   \n",
      "1             198                 47           245    0.000030     0.000028   \n",
      "2             236                 59           295    0.000035     0.000035   \n",
      "3             217                 71           288    0.000033     0.000043   \n",
      "4             220                 43           263    0.000033     0.000026   \n",
      "..            ...                ...           ...         ...          ...   \n",
      "95            216                 46           262    0.000032     0.000028   \n",
      "96            222                 49           271    0.000033     0.000029   \n",
      "97            217                 55           272    0.000033     0.000033   \n",
      "98            231                 56           287    0.000035     0.000034   \n",
      "99            220                 57           277    0.000033     0.000034   \n",
      "\n",
      "    total_cost  \n",
      "0     0.000066  \n",
      "1     0.000058  \n",
      "2     0.000071  \n",
      "3     0.000075  \n",
      "4     0.000059  \n",
      "..         ...  \n",
      "95    0.000060  \n",
      "96    0.000063  \n",
      "97    0.000066  \n",
      "98    0.000068  \n",
      "99    0.000067  \n",
      "\n",
      "[100 rows x 6 columns]\n",
      "\n",
      "Cost Summary:\n",
      "   Total Input Cost  Total Output Cost  Total Cost\n",
      "0           0.00325            0.00332     0.00657\n"
     ]
    }
   ],
   "source": [
    "#calculation of costs\n",
    "price_per_input = 0.150  # price per 1M input tokens\n",
    "price_per_output = 0.600  # price per 1M output tokens\n",
    "\n",
    "# Calculate costs\n",
    "df_tokens_with_costs, cost_summary = calculate_token_costs(df_tokens, price_per_input, price_per_output)\n",
    "\n",
    "# Display results\n",
    "print(\"Tokens with Costs:\")\n",
    "print(df_tokens_with_costs)\n",
    "\n",
    "print(\"\\nCost Summary:\")\n",
    "print(cost_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b2dbca-80ef-427e-b7a0-7030ab9688f1",
   "metadata": {},
   "source": [
    "evaluations = []\n",
    "\n",
    "# Assuming df_eval is your DataFrame with the relevant structure\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "\n",
    "    # Lookup the answer in df_eval based on the question\n",
    "    answer_row = df_eval[df_eval['question'] == question]\n",
    "\n",
    "    if not answer_row.empty:\n",
    "        answer_llm = answer_row['answer'].values[0]  # Get the answer from the DataFrame\n",
    "    else:\n",
    "        answer_llm = \"No answer found\"  # Handle case where question is not in DataFrame\n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "#control of tokens used for the query to see cost of api calls\n",
    "    evaluation,tokens = llm(prompt, model_2)  # Here the model as judge that decides the relevance of the questions\n",
    "\n",
    "    # Call the parsing function robust_json_loads\n",
    "    success, evaluation, error_message = robust_json_loads(evaluation)\n",
    "\n",
    "    evaluations.append((record, answer_llm, evaluation))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29438c85-b1a4-49e8-8607-c378af1ed914",
   "metadata": {},
   "source": [
    "#evaluations_gpt4o = []\n",
    "#evaluations_llama31_8b = []\n",
    "#now with 4o-mini\n",
    "evaluations = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question,model_1) #here the model that creates the question\n",
    "    #answer_llm = robust_json_loads(answer_llm)\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt, model_2) #here the model as judge that decides the relevance of the questions\n",
    "    #evaluation = json.loads(evaluation)\n",
    "    #evaluation = robust_json_loads(evaluation)\n",
    "    # Call the parsing function robust_json_loads\n",
    "    success, evaluation, error_message = robust_json_loads(evaluation)\n",
    "\n",
    "    evaluations.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3f204d0f-517f-4e0b-975d-19b500cdaef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations_gpt4o=evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "04e864b5-0061-4ae3-925a-7064fa0394e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations_gpt4o, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b769bffd-2a2c-4a60-b53b-932aa9105e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tokenization, parsing, named entity recognition.</td>\n",
       "      <td>149</td>\n",
       "      <td>List common NLP tasks supported by Apache Open...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The generated answer lists some common NLP tas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Break exits loop prematurely.</td>\n",
       "      <td>135</td>\n",
       "      <td>What happens when you use the break statement ...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer accurately describes the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patterns and relationships are discovered with...</td>\n",
       "      <td>170</td>\n",
       "      <td>Can you describe a scenario where patterns and...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The answer mentions transfer learning in compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The S-curve serves as a visual tool for analyz...</td>\n",
       "      <td>152</td>\n",
       "      <td>How is an S-curve used for trend analysis and ...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The generated answer mentions the S-curve as a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A confidence interval is a range of values tha...</td>\n",
       "      <td>68</td>\n",
       "      <td>What is a range of values that likely contains...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer accurately defines a conf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Generalized linear models differ from traditio...</td>\n",
       "      <td>147</td>\n",
       "      <td>How do generalized linear models differ from t...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer accurately describes a ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Semi-supervised learning integrates both label...</td>\n",
       "      <td>4</td>\n",
       "      <td>What is semi-supervised learning?</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer accurately defines semi-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>The factors influencing chart creation are the...</td>\n",
       "      <td>64</td>\n",
       "      <td>What factors influence chart creation?</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Grid Search, Random Search, Bayesian Optimizat...</td>\n",
       "      <td>125</td>\n",
       "      <td>List different methods to find optimal hyperpa...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer lists different methods f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Each category is represented by a binary vecto...</td>\n",
       "      <td>173</td>\n",
       "      <td>How are categories represented in one-hot enco...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer accurately describes how ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               answer   id  \\\n",
       "0    Tokenization, parsing, named entity recognition.  149   \n",
       "1                       Break exits loop prematurely.  135   \n",
       "2   Patterns and relationships are discovered with...  170   \n",
       "3   The S-curve serves as a visual tool for analyz...  152   \n",
       "4   A confidence interval is a range of values tha...   68   \n",
       "..                                                ...  ...   \n",
       "95  Generalized linear models differ from traditio...  147   \n",
       "96  Semi-supervised learning integrates both label...    4   \n",
       "97  The factors influencing chart creation are the...   64   \n",
       "98  Grid Search, Random Search, Bayesian Optimizat...  125   \n",
       "99  Each category is represented by a binary vecto...  173   \n",
       "\n",
       "                                             question        relevance  \\\n",
       "0   List common NLP tasks supported by Apache Open...  PARTLY_RELEVANT   \n",
       "1   What happens when you use the break statement ...         RELEVANT   \n",
       "2   Can you describe a scenario where patterns and...  PARTLY_RELEVANT   \n",
       "3   How is an S-curve used for trend analysis and ...  PARTLY_RELEVANT   \n",
       "4   What is a range of values that likely contains...         RELEVANT   \n",
       "..                                                ...              ...   \n",
       "95  How do generalized linear models differ from t...         RELEVANT   \n",
       "96                  What is semi-supervised learning?         RELEVANT   \n",
       "97             What factors influence chart creation?         RELEVANT   \n",
       "98  List different methods to find optimal hyperpa...         RELEVANT   \n",
       "99  How are categories represented in one-hot enco...         RELEVANT   \n",
       "\n",
       "                                          explanation  \n",
       "0   The generated answer lists some common NLP tas...  \n",
       "1   The generated answer accurately describes the ...  \n",
       "2   The answer mentions transfer learning in compu...  \n",
       "3   The generated answer mentions the S-curve as a...  \n",
       "4   The generated answer accurately defines a conf...  \n",
       "..                                                ...  \n",
       "95  The generated answer accurately describes a ke...  \n",
       "96  The generated answer accurately defines semi-s...  \n",
       "97  The generated answer directly addresses the qu...  \n",
       "98  The generated answer lists different methods f...  \n",
       "99  The generated answer accurately describes how ...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c54ecf16-8859-47a8-8bcc-4226c9214498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           75\n",
       "PARTLY_RELEVANT    24\n",
       "NON_RELEVANT        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9ff27bcc-d843-499b-abf9-ff936303af22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.75\n",
       "PARTLY_RELEVANT    0.24\n",
       "NON_RELEVANT       0.01\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ade00f45-1aaf-4236-9452-cdd4bb47fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv('../data/rag-eval-gpt-4o.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4859cf7a-e4da-4b70-85f9-222a335571c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we observe that with the 2 judges, llama 3.1 8b and openai 4o mini there is no irrelevant response\n",
    "#for the small sample with only 5 examples is 80-20 and 60-40 respectively\n",
    "#now with the sample = 100\n",
    "#llama3.1:8b as generator and judge: 80%-20% and only 1 irrelevant\n",
    "#llama3.1:8b as generator and gpt-4o-mini as judge: aprox 75%-25% and only 1 irrelevant answer\n",
    "#the irrelevant one is the only that the generator did not answer for not having enough context\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
