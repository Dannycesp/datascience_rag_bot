{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f35b1666-5393-458a-b747-177c1a1525ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5babe3a1-3d8b-428a-92a8-5fc2285fc494",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data.csv')\n",
    "documents = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdfc5ea2-2895-4ac9-838b-da6181943475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "#source ./bin/activate from project folder before to activate environment\n",
    "load_dotenv()  # Loads the variables from .env file\n",
    "\n",
    "# Now you can access the API_KEY\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d9752d8-ab2f-48d4-a3d9-fa33edb52c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an expert and teacher in datascience, machine learning and artificial intelligence.\n",
    "Your need to widen a set of questions out of a dataset of questions asked in past exams.\n",
    "So for each question you have you want some other equivalent questions to ask, for which the answer is the same as in the original question.\n",
    "Below you have a record with Question and Answer, so you have to reformulate the question so the answer is in the answer in the record. It is\n",
    "mandatory that the reformulated question can be answered with the Answer in the record as the exams will automatically validate the answer as correct.\n",
    "The number of questions to create are 3 for each record.\n",
    "The questions should be complete and not too short. Use as fewer words as possible from the record. \n",
    "\n",
    "\n",
    "The record:\n",
    "Question: {Question}\n",
    "Answer: {Answer}\n",
    "\n",
    "Just output the the json object without any further comments before or after. The key will be \"questions\" and the value the list of questions:\n",
    "    \n",
    "{{\"questions\": [\"question_1\", \"question_2\", \"question_3\"]}}\n",
    "\n",
    "\n",
    "\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f07f48f9-d611-4a47-bd62-f75731608ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=69\n",
    "prompt = prompt_template.format(**documents[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f8699197-4772-4770-a8b8-49adb20fad00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 70,\n",
       " 'Question': \"Elaborate on Python's role in enabling data engineers.\",\n",
       " 'Answer': 'Python empowers data engineers by providing robust libraries such as NumPy, pandas, and scipy, which offer efficient tools for data processing, statistical analysis, and data preparation tasks. NumPy enables numerical computations and array operations, pandas facilitates data manipulation and analysis through DataFrame objects, while scipy offers scientific computing functionalities. Leveraging these libraries, data engineers can streamline data workflows, extract meaningful insights, and prepare data for downstream tasks such as machine learning and analytics, enhancing productivity and efficiency in data-driven projects.'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c01742ee-024b-4908-a7a0-d786e04d9dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model='llama3.1:8b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4df0d7da-bcc1-45a8-9336-3652a97c5643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e67d59-baa5-41d3-8461-1b7a0338329f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c99a4a35-666a-40e6-9037-789acc301293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "#client = OpenAI()\n",
    "def llm(prompt, model=model):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0.0,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6534a160-f763-4d21-8176-4bed6326bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a24452a0-abc1-4257-a0fc-9bdf5e0a981b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an expert and teacher in datascience, machine learning and artificial intelligence.\\nYour need to widen a set of questions out of a dataset of questions asked in past exams.\\nSo for each question you have you want some other equivalent questions to ask, for which the answer is the same as in the original question.\\nBelow you have a record with Question and Answer, so you have to reformulate the question so the answer is in the answer in the record. It is\\nmandatory that the reformulated question can be answered with the Answer in the record as the exams will automatically validate the answer as correct.\\nThe number of questions to create are 3 for each record.\\nThe questions should be complete and not too short. Use as fewer words as possible from the record. \\n\\n\\nThe record:\\nQuestion: Elaborate on Python\\'s role in enabling data engineers.\\nAnswer: Python empowers data engineers by providing robust libraries such as NumPy, pandas, and scipy, which offer efficient tools for data processing, statistical analysis, and data preparation tasks. NumPy enables numerical computations and array operations, pandas facilitates data manipulation and analysis through DataFrame objects, while scipy offers scientific computing functionalities. Leveraging these libraries, data engineers can streamline data workflows, extract meaningful insights, and prepare data for downstream tasks such as machine learning and analytics, enhancing productivity and efficiency in data-driven projects.\\n\\nJust output the the json object without any further comments before or after. The key will be \"questions\" and the value the list of questions:\\n    \\n{\"questions\": [\"question_1\", \"question_2\", \"question_3\"]}'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6037e43d-b505-43e3-bf7d-c0a6d3be028b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"questions\": [\\n    \"What tools enable data engineers to process, analyze, and prepare data efficiently?\",\\n    \"How do libraries like NumPy, pandas, and scipy support data engineering tasks?\",\\n    \"What benefits can data engineers gain from leveraging these scientific computing libraries?\"\\n]}'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c0a5cd97-3e7b-4b62-ba82-6f7adbbcca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after many iterations this is the function that works better when the output of the llm is not correctly formatted\n",
    "#and we have more control of which outputs failed as we save the errors and the program continue even if some\n",
    "#outputs failed\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "def robust_json_loads(s):\n",
    "    \"\"\"\n",
    "    Attempts to parse a JSON string, fixing common errors if parsing fails.\n",
    "\n",
    "    Parameters:\n",
    "    s (str): The JSON string to parse.\n",
    "\n",
    "    Returns:\n",
    "    tuple: (success (bool), data (dict or None), error_message (str or None))\n",
    "    \"\"\"\n",
    "    original_s = s  # Keep a copy of the original string\n",
    "\n",
    "    # First, attempt to parse the input string directly\n",
    "    try:\n",
    "        data = json.loads(s)\n",
    "        return (True, data, None)\n",
    "    except json.JSONDecodeError:\n",
    "        pass  # Proceed to cleaning steps if parsing fails\n",
    "\n",
    "    # Step 1: Strip wrapping backticks and language specifiers\n",
    "    s = s.strip()\n",
    "    s = re.sub(r'^```[a-zA-Z]*\\s*', '', s)  # Remove starting triple backticks and optional language\n",
    "    s = re.sub(r'```$', '', s)              # Remove ending triple backticks\n",
    "    s = s.strip('`')                        # Remove any remaining backticks\n",
    "\n",
    "    # Step 2: Remove any text before the first '{' or '['\n",
    "    start_idx = re.search(r'[\\{\\[]', s)\n",
    "    if not start_idx:\n",
    "        error_message = \"No JSON object could be detected in the input.\"\n",
    "        return (False, None, error_message)\n",
    "    s = s[start_idx.start():]\n",
    "\n",
    "    # Step 3: Remove any text after the last '}' or ']'\n",
    "    end_idx = max(s.rfind('}'), s.rfind(']'))\n",
    "    if end_idx == -1:\n",
    "        error_message = \"No JSON object could be detected in the input.\"\n",
    "        return (False, None, error_message)\n",
    "    s = s[:end_idx+1]\n",
    "\n",
    "    # Step 4: Remove extraneous characters after the JSON content\n",
    "    # Remove any characters after the last closing brace/bracket\n",
    "    s = re.sub(r'([\\}\\]])[\\s\\S]*$', r'\\1', s)\n",
    "\n",
    "    # Step 5: Remove extraneous characters before the JSON content\n",
    "    # Remove any characters before the first opening brace/bracket\n",
    "    s = re.sub(r'^[\\s\\S]*?([\\{\\[])', r'\\1', s)\n",
    "\n",
    "    # Step 6: Replace single quotes with double quotes for keys and values\n",
    "    # Avoid changing single quotes inside double-quoted strings\n",
    "    s = re.sub(\n",
    "        r'(?<=[:\\{\\[,])\\s*\\'([^\\']*)\\'\\s*(?=[:,\\}\\]])',\n",
    "        r'\"\\1\"',\n",
    "        s\n",
    "    )\n",
    "\n",
    "    # Step 7: Remove trailing commas before closing braces/brackets\n",
    "    s = re.sub(r',\\s*(\\}|\\])', r'\\1', s)\n",
    "\n",
    "    # Step 8: Balance brackets and braces if necessary\n",
    "    def balance_characters(s, open_char, close_char):\n",
    "        opens = s.count(open_char)\n",
    "        closes = s.count(close_char)\n",
    "        if opens > closes:\n",
    "            s += close_char * (opens - closes)\n",
    "        elif closes > opens:\n",
    "            s = open_char * (closes - opens) + s\n",
    "        return s\n",
    "\n",
    "    s = balance_characters(s, '{', '}')\n",
    "    s = balance_characters(s, '[', ']')\n",
    "\n",
    "    # Step 9: Remove unescaped control characters\n",
    "    # Control characters are not allowed in JSON strings\n",
    "    s = re.sub(r'[\\x00-\\x1F]+', '', s)\n",
    "\n",
    "    # Step 10: Final check to remove extra double quotes at the end of strings in arrays\n",
    "    # This targets the specific case you mentioned\n",
    "    s = re.sub(r'(\".*?\")\"+(?=\\s*[\\],}])', r'\\1', s)\n",
    "\n",
    "    # Step 11: Attempt to parse the cleaned string\n",
    "    try:\n",
    "        data = json.loads(s)\n",
    "    except json.JSONDecodeError as e:\n",
    "        error_message = f\"Error parsing JSON after cleaning: {e}\"\n",
    "        return (False, None, error_message)\n",
    "\n",
    "    # Validate that the parsed data contains the expected 'questions' key\n",
    "    if not isinstance(data, dict) or 'questions' not in data:\n",
    "        error_message = \"Parsed JSON does not contain 'questions' key.\"\n",
    "        return (False, None, error_message)\n",
    "\n",
    "    # Check that 'questions' is a non-empty list\n",
    "    if not isinstance(data['questions'], list) or not data['questions']:\n",
    "        error_message = \"'questions' key is empty or not a list.\"\n",
    "        return (False, None, error_message)\n",
    "\n",
    "    # Parsing and validation successful\n",
    "    return (True, data, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "78d649f7-5c80-4730-94fd-1dd4a9f8fb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " {'questions': ['What tools enable data engineers to process, analyze, and prepare data efficiently?',\n",
       "   'How do libraries like NumPy, pandas, and scipy support data engineering tasks?',\n",
       "   'What benefits can data engineers gain from leveraging these scientific computing libraries?']},\n",
       " None)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_question = robust_json_loads(questions)\n",
    "parsed_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b719d997-2140-4fa5-8e14-2eeba3792ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "634193b7-681b-41c9-8fc9-f6f43d5cf2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we are going to  make a test using only a part of the dataset for not incurring in the cost of processing the whole 1000+ records\n",
    "documents_test = documents[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f82c4a84-b0c5-4013-938f-b380884d8663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'Question': 'What is under-fitting and overfitting in machine learning?',\n",
       "  'Answer': \"Underfitting is when a model is too simple, and overfitting is when it's too complex, making it perform poorly on new data.\"},\n",
       " {'id': 2,\n",
       "  'Question': 'Can you explain what a false positive and a false negative are?',\n",
       "  'Answer': \"A false positive incorrectly indicates a condition is present when it's not, while a false negative misses detecting a condition that is there.\"},\n",
       " {'id': 3,\n",
       "  'Question': 'Clarify the concept of Phase IV.',\n",
       "  'Answer': \"Phase IV studies, also known as post-marketing surveillance, are conducted after a drug or medical product is made available to the general public. They aim to monitor the product's safety, efficacy, and long-term effects in a larger and more diverse population, providing valuable insights into real-world usage. Phase IV studies help regulators, healthcare providers, and patients make informed decisions about the product's continued use by assessing its risks and benefits over an extended period outside the controlled environment of clinical trials.\"},\n",
       " {'id': 4,\n",
       "  'Question': 'What is semi-supervised learning described in a short description?',\n",
       "  'Answer': 'Semi-supervised learning integrates both labeled and unlabeled data during model training. By leveraging the abundance of unlabeled data alongside limited labeled data, it enhances model performance and generalization to new examples, offering scalability and efficiency in scenarios where acquiring labeled data is resource-intensive or impractical. This approach bridges the gap between supervised and unsupervised learning, unlocking the potential of vast unlabeled datasets for training robust machine learning models.'},\n",
       " {'id': 5,\n",
       "  'Question': 'Discuss the parallelization of training in gradient boosting models.',\n",
       "  'Answer': \"Parallelizing training of a gradient boosting model is indeed possible, leveraging the parallel processing capabilities of modern hardware, such as GPUs. Frameworks like XGBoost offer options like 'tree_method = 'gpu_hist'' to utilize GPUs for faster training. By distributing computation across multiple cores or devices simultaneously, parallelization accelerates the training process, significantly reducing training time and improving efficiency. This approach is particularly beneficial for large datasets and complex models, where traditional sequential training may be computationally intensive and time-consuming.\"}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d95afcdc-9382-4d75-b0e3-3e7cd72feba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dan/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9eed0e63-1e1d-449a-89e2-d6c3a8af60ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "89353974-26a6-4ada-b488-adb281c17999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(doc):\n",
    "    \n",
    "    prompt = prompt_template.format(**doc)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0.0,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    json_response = response.choices[0].message.content\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "51d1c082-057b-49bb-beb9-cea85b9e19f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_documents(documents, results, limit=None):\n",
    "    # Pre-compute the set of doc_ids that are already in results\n",
    "    existing_ids = set(results.keys())\n",
    "    \n",
    "    # Determine the number of documents to process\n",
    "    num_documents_to_process = len(documents) if limit is None else min(len(documents), limit)\n",
    "\n",
    "    # List to store problematic inputs and their error messages\n",
    "    failed_records = []\n",
    "\n",
    "    # Loop through only the required number of documents\n",
    "    for i, doc in enumerate(tqdm(documents[:num_documents_to_process])):\n",
    "        doc_id = doc['id']\n",
    "        \n",
    "        # Skip processing if doc_id is already in results\n",
    "        if doc_id in existing_ids:\n",
    "            continue\n",
    "        \n",
    "        # Generate questions and process\n",
    "        questions_raw = generate_questions(doc)\n",
    "        success, data, error_message = robust_json_loads(questions_raw)\n",
    "        \n",
    "        if success:\n",
    "            # Add results to the dictionary\n",
    "            results[doc_id] = data['questions']\n",
    "        else:\n",
    "            # Save the problematic input and error message\n",
    "            failed_records.append({\n",
    "                'doc_id': doc_id,\n",
    "                'questions_raw': questions_raw,\n",
    "                'error_message': error_message\n",
    "            })\n",
    "            # Optionally, add an error message in results\n",
    "            results[doc_id] = f\"Error processing document: {error_message}\"\n",
    "\n",
    "    # Return the failed records for further inspection\n",
    "    return failed_records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3643dccd-9a11-483c-9053-5ca741b107e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ CALL TO THE LLM FOR ALL THE DOCS OR PART #####################3333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "03c8c25b-8365-49ee-88b8-3c6c7c6facd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [02:39<00:00,  1.25it/s]\n"
     ]
    }
   ],
   "source": [
    "#as the llm fails sometimes to give a valid structure, even when we have made a robust_json_loads() that success\n",
    "#to parse most of the time(only 2 errors in 74 documents, many more if we do not use this robust_json function\n",
    "#we now detect the failed records and save a dummy error message and the failed records in a dataframe for debugging\n",
    "\n",
    "##UPDATE: with the last robust_json_loads() version and model llama3.1 8b and temmperature=0 -->100% success, not even one failed!\n",
    "#and checking the outputs seem quite right and logic and related to the original question-answer\n",
    "\n",
    "# Process the documents, add limit to process part of the docs\n",
    "failed_records = process_documents(documents, results, limit=200)\n",
    "\n",
    "# Convert failed_records to a DataFrame for easier inspection\n",
    "\n",
    "failed_df = pd.DataFrame(failed_records)\n",
    "\n",
    "# Save the failed records to a CSV file for further analysis\n",
    "failed_df.to_csv('failed_records.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5844a7e8-1127-445d-b5ac-0f634c637382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(failed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "62a883f0-b981-4486-973f-99acd589c679",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#to process the numnber of docs for testing purposes\n",
    "#process_documents(documents, results, limit=100)\n",
    "#process_documents(documents, results)  # Will process all documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5d8db4eb-7e77-4fd7-a6b0-c1034cbe4de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#now that the robust parser seems to work fine almost 100% we eliminate from results the errors or empty lines if any\n",
    "#delete the keys with error to reprocess documents and then reorder results with the ids\n",
    "\n",
    "# Identify failed doc_ids\n",
    "failed_doc_ids = [\n",
    "    doc_id for doc_id, value in results.items()\n",
    "    if (isinstance(value, str) and value.startswith('Error processing document'))\n",
    "    or (isinstance(value, list) and not value)  # Empty list\n",
    "]\n",
    "print(failed_doc_ids)\n",
    "\n",
    "# Remove failed doc_ids from results\n",
    "for doc_id in failed_doc_ids:\n",
    "    results.pop(doc_id, None)  # Remove the failed doc_id from results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "81e367ec-d6ed-462d-83e5-9336c1f45a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 1/1 [00:00<00:00, 22919.69it/s]\n"
     ]
    }
   ],
   "source": [
    "#reprocessing of results to add the keys with previous errors that were deleted\n",
    "# Re-run process_documents on the entire documents list\n",
    "# Process the documents\n",
    "failed_records = process_documents(documents, results, limit=1)\n",
    "\n",
    "# Convert failed_records to a DataFrame for easier inspection\n",
    "#import pandas as pd\n",
    "failed_df = pd.DataFrame(failed_records)\n",
    "\n",
    "# Save the failed records to a CSV file for further analysis\n",
    "failed_df.to_csv('failed_records.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "42ca5a7f-12cd-4b27-932e-d6614e1259ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ae0f0573-4460-4d76-827d-a012e2ec6ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 What happens when a machine learning model is too simple?\n",
      "1 How does overfitting affect a model's performance on new data?\n",
      "1 Can a model be too complex, and if so, what are the consequences?\n",
      "2 What are the implications of a test result that incorrectly suggests a condition's presence?\n",
      "2 How does a false indication of a condition's absence impact diagnosis and treatment?\n",
      "2 Can you describe a situation where a medical test fails to detect an actual condition?\n",
      "3 What type of studies are conducted after a drug or medical product is made available to the general public?\n",
      "3 What is the primary goal of Phase IV studies in terms of monitoring a product's safety and efficacy?\n",
      "3 How do Phase IV studies contribute to informed decision-making about a product's continued use?\n",
      "4 What is semi-supervised learning?\n",
      "4 How does semi-supervised learning improve model performance?\n",
      "4 What are the benefits of using unlabeled data in machine learning?\n",
      "5 How can gradient boosting models take advantage of modern hardware?\n",
      "5 What options are available in XGBoost to utilize GPUs for faster training?\n",
      "5 In what scenarios is parallelizing the training process particularly beneficial?\n",
      "6 What is a single file that encapsulates specific functionalities in Python?\n",
      "6 How does a collection of related modules differ from a single file in Python?\n",
      "6 What can be reused in different programs when using a Python module?\n",
      "7 What does power in frequentist statistics refer to?\n",
      "7 How does sample size affect a test's ability to detect an effect?\n",
      "7 What happens when a study has low power?\n",
      "8 How does Python handle function arguments?\n",
      "8 What is the nature of variable passing in Python functions?\n",
      "8 Can you explain how mutable and immutable data affect argument passing in Python?\n",
      "9 What type of error occurs due to chance or variability in sampling?\n",
      "9 How do unpredictable factors affect measurements or observations?\n",
      "9 What is the primary goal when trying to minimize random errors?\n",
      "10 What type of graphical representation shows data distribution?\n",
      "10 How is numerical data typically depicted in a histogram?\n",
      "10 What visual tool provides insights into data concentration and frequency?\n",
      "11 What algorithm predicts text tags based on probabilities?\n",
      "11 How is Naive Bayes used in Natural Language Processing tasks?\n",
      "11 In NLP, what does the Naive Bayes algorithm classify?\n",
      "12 What is the purpose of random initialization in neural networks?\n",
      "12 How does symmetry affect feature representation in a neural network?\n",
      "12 What role do unique signals play in effective learning and model convergence?\n",
      "13 What statistical methods can prove males are taller on average?\n",
      "13 How to statistically show that males have a greater average height than females?\n",
      "13 Can a t-test be used to demonstrate the difference in average heights between males and females?\n",
      "14 What techniques can reduce noise in a time series dataset?\n",
      "14 How can data normalization help manage outliers in time series analysis?\n",
      "14 Which statistical models are robust against anomalies in time series data?\n",
      "15 What type of plot displays two quantitative variables?\n",
      "15 How can you visualize patterns in data using two numerical values?\n",
      "15 What graph allows you to see correlations between two continuous variables?\n",
      "16 What is the purpose of using groupby in data analysis?\n",
      "16 How does groupby facilitate summarizing data based on categories?\n",
      "16 What aggregate functions can be applied to each group using groupby?\n",
      "17 Which statistical tests are used to identify relevant features in feature selection?\n",
      "17 How do wrapper methods iteratively add or remove features based on model performance?\n",
      "17 What is the process of selecting variables that involves filter and wrapper methods?\n",
      "18 What technique in machine learning maps categorical data into a lower-dimensional space?\n",
      "18 How do embeddings facilitate models to process and learn from high-dimensional categorical data?\n",
      "18 In what way can embeddings improve the performance of machine learning models?\n",
      "19 What models can generate samples from a learned joint probability distribution?\n",
      "19 Which type of model is primarily used for classification tasks, focusing on decision boundaries between classes?\n",
      "19 What is the primary difference in how generative and discriminative models capture data generation processes?\n",
      "20 Describe a basic neural network's operation.\n",
      "20 What is the process by which a basic neural network generates an output?\n",
      "20 How does a basic neural network learn patterns from data?\n",
      "21 What is the role of softmax in neural network output?\n",
      "21 How does softmax function affect neural network predictions?\n",
      "21 What transformation does softmax apply to neural network outputs?\n",
      "22 What is the IQR used to measure?\n",
      "22 How is the interquartile range calculated?\n",
      "22 Why is the IQR useful in statistical analysis?\n",
      "23 What is the average difference between predicted and actual values in a dataset?\n",
      "23 How does Mean Absolute Error (MAE) measure prediction accuracy in regression tasks?\n",
      "23 What is the typical magnitude of errors in a model's predictions, as quantified by MAE?\n",
      "24 What type of algorithms are modeled loosely after the human brain?\n",
      "24 How do computers recognize patterns using a specific set of algorithms?\n",
      "24 What is the primary function of neural networks in problem-solving?\n",
      "25 What data points are used together in one machine learning model training iteration?\n",
      "25 How many data points make up a batch for machine learning model training?\n",
      "25 In machine learning, what is the term for the number of data points used in each model training iteration?\n",
      "26 What techniques are used to artificially expand a training dataset?\n",
      "26 How does data augmentation improve model robustness?\n",
      "26 What is the primary goal of image augmentation in machine learning?\n",
      "27 What is NLTK used for in NLP?\n",
      "27 NLTK stands for what in Python?\n",
      "27 What programming language does NLTK use?\n",
      "28 What technique reduces text data dimensions to capture underlying meaning?\n",
      "28 How does LSI improve search accuracy in text data?\n",
      "28 What is the primary goal of applying Latent Semantic Indexing?\n",
      "29 What enables computers to understand human language?\n",
      "29 How do NLP systems process text and speech data?\n",
      "29 What tasks does NLP encompass, including language translation and sentiment analysis?\n",
      "30 What is a structured set of data used for machine learning?\n",
      "30 Describe the format in which datasets are typically stored.\n",
      "30 What is inputted into machine learning models?\n",
      "31 What patterns can models identify in data?\n",
      "31 How do unsupervised learning algorithms reveal hidden insights?\n",
      "31 What tasks are facilitated by exploring data's inherent structure?\n",
      "32 What is requirement prioritization in business and software development?\n",
      "32 List techniques used for deciding importance of requirements based on impact and urgency.\n",
      "32 How do stakeholders determine the order of fulfilling business or software development requirements?\n",
      "33 What techniques can reduce overfitting in SVM models?\n",
      "33 How does dimensionality reduction impact computational efficiency in SVM?\n",
      "33 Can high-dimensional datasets benefit from preprocessing before applying an SVM?\n",
      "34 What makes Apache Spark faster than MapReduce?\n",
      "34 How does in-memory processing improve data analysis with Spark?\n",
      "34 What type of algorithms benefit from Spark's iterative capabilities?\n",
      "35 What is the purpose of rates in various fields?\n",
      "35 How do rates differ from probabilities?\n",
      "35 What kind of insights do rates provide about events?\n",
      "36 What characteristic makes a model prone to overfitting?\n",
      "36 How do higher capacity models differ from lower ones in terms of data learning?\n",
      "36 What happens when a high-capacity model is not properly regularized?\n",
      "37 What is the core concept behind transformer models?\n",
      "37 How do transformer models improve NLP tasks?\n",
      "37 What is the key innovation in transformer models that leads to state-of-the-art performance?\n",
      "38 What are the primary differences between collaborative filtering and content-based filtering?\n",
      "38 How do collaborative filtering and content-based filtering approach personalized recommendations?\n",
      "38 In what ways do collaborative filtering and content-based filtering diverge in their recommendation strategies?\n",
      "39 What ensemble strategy reduces variance by averaging predictions from various models trained on different subsets of data?\n",
      "39 How do bagging algorithms handle examples that previous models got wrong?\n",
      "39 Can you describe an approach to sequentially train models with a focus on examples the previous models got wrong?\n",
      "40 What is the purpose of FSCK?\n",
      "40 Describe the function of a File System Consistency Check.\n",
      "40 What does the system utility FSCK do?\n",
      "41 What statistical methods are used in linear regression?\n",
      "41 How does OLS minimize distance between actual and predicted values?\n",
      "41 What is the primary goal of maximum likelihood estimation in logistic regression?\n",
      "42 What is the primary characteristic of a star schema?\n",
      "42 How does the snowflake schema differ from the star schema in terms of data redundancy?\n",
      "42 Which database design approach typically results in faster query speeds but may lead to data redundancy?\n",
      "43 What mathematical model makes specific assumptions about data distribution?\n",
      "43 How many parameters does a parametric model have?\n",
      "43 What is the relationship between input and output variables in a parametric model?\n",
      "44 What role does game theory play in developing strategies for autonomous agents?\n",
      "44 How is game theory applied to analyze decision-making processes among multiple decision-makers?\n",
      "44 In what ways can game theory influence AI applications like negotiation algorithms?\n",
      "45 What is an autonomous entity in AI that perceives surroundings through sensors?\n",
      "45 How do agents in AI achieve predefined goals?\n",
      "45 What type of learning improves agent actions based on feedback?\n",
      "46 What statistical methods are used to determine if a sample's characteristics can be generalized to the entire population?\n",
      "46 Which tests are employed to assess assumptions related to means, variances, and distributions in data analysis?\n",
      "46 Can you describe the process of evaluating evidence from a sample to make conclusions about the population?\n",
      "47 What strategies can be employed to handle missing values in a dataset?\n",
      "47 How do you replace missing numerical data without disrupting the data distribution?\n",
      "47 When is it appropriate to exclude a variable from analysis due to excessive missing data?\n",
      "48 What is a fundamental concept in TensorFlow that represents computational operations?\n",
      "48 In the context of TensorFlow, what does a graph define?\n",
      "48 How are nodes and edges related in a TensorFlow graph?\n",
      "49 What method compares two webpage versions to determine which one performs better?\n",
      "49 How do you decide which product feature is more effective in terms of conversion rates?\n",
      "49 What statistical technique helps choose between two different versions of a product or service?\n",
      "50 What does statistical power measure in hypothesis testing?\n",
      "50 Why is it crucial to consider statistical power in experimental design?\n",
      "50 How does statistical power relate to rejecting a null hypothesis when an alternative holds?\n",
      "51 What underlying constructs influence observed data?\n",
      "51 How do latent variables explain patterns in statistical models?\n",
      "51 What statistical techniques can be used to infer the values of unobservable variables?\n",
      "52 What is the purpose of dependency parsing in natural language processing?\n",
      "52 How do words relate to each other in a sentence according to dependency parsing?\n",
      "52 In NLP, what technique maps out the grammatical structure of sentences?\n",
      "53 What types of transformations can SVM perform on data?\n",
      "53 How do kernels enable complex classification in SVM?\n",
      "53 Which kernel is similar to a neural network?\n",
      "54 What happens when a subset of data is chosen for analysis without considering the entire population?\n",
      "54 How can selecting non-representative participants affect the validity of study conclusions?\n",
      "54 What type of bias occurs when the selected data does not accurately reflect the overall population?\n",
      "55 What method is used during model training to selectively calculate probabilities for all positive class instances and a random subset of negative ones?\n",
      "55 How does candidate sampling effectively manage class imbalance during model training?\n",
      "55 What is the purpose of using candidate sampling in machine learning when dealing with imbalanced datasets?\n",
      "56 What is a concise way to create lists in Python?\n",
      "56 How can you efficiently construct dictionaries in Python?\n",
      "56 What are the benefits of using comprehensions instead of loops and functions?\n",
      "57 What machine learning algorithms are used for regression tasks?\n",
      "57 Which classification algorithms are commonly used in machine learning?\n",
      "57 How do clustering and dimensionality reduction work in unsupervised learning?\n",
      "58 What does variance measure in a dataset?\n",
      "58 How is variance related to data points around the mean?\n",
      "58 What impact does variance have on statistical analyses and decision-making?\n",
      "59 What is the difference between a single element addition and an iterable addition to a list?\n",
      "59 How does append() differ from extend() in terms of data integration?\n",
      "59 In Python, what method is used for adding multiple elements at once to a list?\n",
      "60 What type of reasoning does Statistical AI use?\n",
      "60 How does Classical AI approach problem-solving?\n",
      "60 Can you describe the key difference between Statistical and Classical AI?\n",
      "61 What prevents overfitting in Random Forests?\n",
      "61 How does randomization contribute to model generalization?\n",
      "61 What is the effect of introducing diversity in an ensemble?\n",
      "62 What is a step-by-step procedure for any algorithm?\n",
      "62 How do you implement a Decision Tree in pseudocode?\n",
      "62 Can you describe the process of building a tree-based model?\n",
      "63 What are the benefits of applying dimensionality reduction to an SVM?\n",
      "63 How does PCA/SVD improve SVM's performance in high-dimensional datasets?\n",
      "63 Can you explain how reducing features affects SVM's generalization and scalability?\n",
      "64 What factors influence chart creation?\n",
      "64 How do relationships between variables impact dashboard design?\n",
      "64 What features should a chart or dashboard include for user interactivity?\n",
      "65 What type of data is collected when researchers manipulate variables directly?\n",
      "65 How do experimental studies differ from observational studies in terms of establishing causality?\n",
      "65 Why is it essential to understand the distinction between experimental and observational data?\n",
      "66 What data visualization technique is used to highlight trends?\n",
      "66 How can conditional formatting aid in anomaly detection?\n",
      "66 What is the purpose of using conditional formatting in a dataset?\n",
      "67 What is a regression method used for survival analysis?\n",
      "67 Which statistical model relates various factors to the time until an event occurs?\n",
      "67 How does the Cox model handle censored data?\n",
      "68 What is a range of values that likely contains the population parameter?\n",
      "68 How does sample variability affect the population parameter?\n",
      "68 What statistical concept accounts for uncertainty in sample data?\n",
      "69 What are the primary differences between machine learning and deep learning?\n",
      "69 How do machine learning and deep learning models approach feature extraction?\n",
      "69 In what scenarios is deep learning more suitable than traditional machine learning?\n",
      "70 What tools enable data engineers to process, analyze, and prepare data efficiently?\n",
      "70 How do libraries like NumPy, pandas, and scipy support data engineering tasks?\n",
      "70 What benefits can data engineers gain from leveraging these scientific computing libraries?\n",
      "71 What is the main goal of combining multiple machine learning models?\n",
      "71 How do ensemble methods improve model performance compared to a single model?\n",
      "71 What benefits can be achieved by using ensemble methods in machine learning?\n",
      "72 What is a basic neural network architecture consisting of a single neuron?\n",
      "72 How does a perceptron approximate binary inputs?\n",
      "72 What are the key components involved in a perceptron's output calculation?\n",
      "73 What is meant by augmented intelligence?\n",
      "73 How does technology assist humans in decision-making through IA?\n",
      "73 Can you describe a scenario where human intelligence is enhanced by technology?\n",
      "74 What are GANs composed of?\n",
      "74 How do Generative Adversarial Networks generate new data?\n",
      "74 Can synthetic instances generated by GANs be distinguished from real data?\n",
      "75 What is the programming language used for NLTK?\n",
      "75 Which natural language processing library is written in Java?\n",
      "75 How do the programming languages of NLTK and OpenNLP differ?\n",
      "76 What algorithm is used to optimize decision-making for game players?\n",
      "76 Explain how a game player can ensure an optimal strategy against an opponent.\n",
      "76 What is the key concept behind a minimax algorithm in game theory?\n",
      "77 What type of study examines historical data to investigate relationships?\n",
      "77 How do researchers typically collect data for retrospective studies?\n",
      "77 What are some potential limitations of retrospective studies?\n",
      "78 What are the primary purposes of data mining and data warehousing?\n",
      "78 How do data mining and data warehousing differ in their approaches to data analysis?\n",
      "78 What role do data mining and data warehousing play in enabling informed decision-making?\n",
      "79 What is the primary difference between processing one observation at a time versus using the entire dataset simultaneously?\n",
      "79 How do online and batch learning approaches differ in terms of data utilization?\n",
      "79 Can you describe the key distinction between handling individual observations versus the entire dataset as a whole?\n",
      "80 What Python libraries are commonly used for data manipulation?\n",
      "80 Which libraries are typically employed in machine learning tasks?\n",
      "80 What frameworks are popularly utilized in deep learning applications?\n",
      "81 What is the purpose of residuals in a statistical model?\n",
      "81 How do residuals relate to the goodness-of-fit and assumptions of regression models?\n",
      "81 What should be the ideal distribution of residuals around zero?\n",
      "82 What measures consistency among human coders?\n",
      "82 How is reliability in human judgments quantified?\n",
      "82 What indicates greater accuracy in assessments?\n",
      "83 What is the primary function of the input layer in neural networks?\n",
      "83 How does the input layer process raw data in a neural network?\n",
      "83 What features are represented by nodes in the input layer?\n",
      "84 What is meant by partitioning a population into distinct subgroups?\n",
      "84 How does stratified sampling ensure proportional representation of various subgroups?\n",
      "84 What are the benefits of using stratified sampling in study results?\n",
      "85 What are the limitations of using mean imputation for missing data?\n",
      "85 How does mean imputation affect the representation of data and its underlying patterns or distributions?\n",
      "85 Why is it generally discouraged to use mean imputation in handling missing data?\n",
      "86 What techniques are used to forecast time series data in machine learning?\n",
      "86 How do autoregressive models contribute to time series forecasting?\n",
      "86 What advanced methods can be employed for complex pattern recognition in sequential data?\n",
      "87 What is the primary purpose of Root Mean Squared Error (RMSE) in regression analysis?\n",
      "87 How does RMSE measure the dispersion or variability of data points around a regression line?\n",
      "87 What does taking the square root of the mean squared error achieve in terms of model performance comparison?\n",
      "88 What does OLAP stand for in data warehousing?\n",
      "88 How do OLAP systems support business intelligence applications?\n",
      "88 What type of analysis is facilitated by OLAP systems?\n",
      "89 What methods can help prevent a model from overfitting?\n",
      "89 How can you ensure a model's performance is not limited to training data?\n",
      "89 What techniques reduce the risk of building overly complex models?\n",
      "90 What type of learning uses labeled data for training?\n",
      "90 How does unsupervised learning handle unlabeled data?\n",
      "90 What are some common tasks that unsupervised learning is useful for?\n",
      "91 What operation allows you to access a single element in a sequence?\n",
      "91 How do you retrieve multiple elements from a sequence at once?\n",
      "91 What is the purpose of using indexing versus slicing in data manipulation?\n",
      "92 What is machine learning and its primary objectives?\n",
      "92 Describe the approach used in machine learning to perform tasks.\n",
      "92 List the techniques and algorithms used for pattern recognition, prediction, and decision-making.\n",
      "93 What direction does the gradient point in for a function?\n",
      "93 How is the gradient used to optimize functions?\n",
      "93 What is the primary purpose of calculating the gradient?\n",
      "94 What is the purpose of retaining information within a defined timeframe?\n",
      "94 How does limited memory impact tasks requiring temporal context or real-time processing?\n",
      "94 What are the key characteristics of systems that can retain information for only a short period?\n",
      "95 What would be the implications of surpassing human cognitive abilities?\n",
      "95 How might artificial intelligence fundamentally alter societal structures?\n",
      "95 What are some potential benefits and risks associated with significantly exceeding human intelligence?\n",
      "96 What tangible outcomes are expected from a project?\n",
      "96 What is handed over to clients or stakeholders upon project completion?\n",
      "96 What objectives must be fulfilled by the end of a project?\n",
      "97 What type of string matching allows for similar but not identical patterns?\n",
      "97 In search functions, what technique is used to identify non-identical strings?\n",
      "97 What data cleaning method uses fuzzy string matching?\n",
      "98 What iterative process updates model parameters to minimize loss?\n",
      "98 How do gradients influence adjustments to weights and biases in a model?\n",
      "98 What is the primary goal of adjusting weights and biases based on computed gradients?\n",
      "99 What happens when a statistical test incorrectly concludes there's an effect?\n",
      "99 How does a Type I error affect our understanding of data?\n",
      "99 What is the probability of mistakenly rejecting the null hypothesis?\n",
      "100 What is a network that makes decisions by considering how changing one piece can affect the whole?\n",
      "100 How does an RBM simplify the decision-making process of a Boltzmann machine?\n",
      "100 What restriction does an RBM impose on the connections between pieces in a Boltzmann machine?\n",
      "101 What variables can lead to misleading associations?\n",
      "101 Which factors must be controlled for in research and statistical analysis?\n",
      "101 How do confounding variables impact dependent and independent variables?\n",
      "102 What is the average magnitude of errors in a predictive model?\n",
      "102 How does MSE penalize larger prediction errors?\n",
      "102 What is commonly used as a loss function in regression and optimization tasks?\n",
      "103 What framework in theoretical computer science provides guarantees on machine learning algorithm efficiency?\n",
      "103 How does PAC learning relate to understanding machine learning algorithms' performance from limited samples?\n",
      "103 What is the main goal of the Probably Approximately Correct (PAC) learning framework?\n",
      "104 What is a concise measure of data spread around its mean?\n",
      "104 How does standard deviation quantify individual data points' distance from the mean?\n",
      "104 What is the typical deviation of data values from their mean, as expressed by standard deviation?\n",
      "105 What type of neural network architecture is designed to process sequential data?\n",
      "105 How do recurrent neural networks differ from feedforward neural networks?\n",
      "105 What are some common tasks that recurrent neural networks are well-suited for?\n",
      "106 What ensemble learning method uses numerous decision trees to reduce overfitting?\n",
      "106 How does an ensemble model improve its ability to generalize?\n",
      "106 What is the primary benefit of using multiple decision trees in a single model?\n",
      "107 What is the probability of observing results as extreme as those obtained under the null hypothesis?\n",
      "107 Under what conditions would we expect to observe results as extreme as those obtained in this scenario?\n",
      "107 What is the likelihood of obtaining results at least as extreme as those observed, assuming the null hypothesis is true?\n",
      "108 What NLP technique involves understanding speaker's goals and context?\n",
      "108 How does one derive intended meaning from a given text in NLP?\n",
      "108 In NLP, what is the process of going beyond literal content to infer meaning?\n",
      "109 What distinguishes a regular expression from another pattern matching tool?\n",
      "109 How does regular grammar differ from string manipulation?\n",
      "109 What is the primary function of regular expressions in text processing?\n",
      "110 What are the distinct phases in a machine learning project?\n",
      "110 How does one ensure high-quality data for modeling purposes?\n",
      "110 What is the process to refine and deploy an effective model?\n",
      "111 What is robotics, in simple terms?\n",
      "111 What are the main goals of robotics technology?\n",
      "111 How does robotics contribute to productivity and safety?\n",
      "112 What types of biases can occur during sampling?\n",
      "112 Which biases in sampling methods can lead to incorrect population representation?\n",
      "112 What are the common pitfalls that can skew results when collecting data?\n",
      "113 What does the ROC curve measure in binary classification?\n",
      "113 When is it appropriate to use a ROC curve for model evaluation?\n",
      "113 What type of outcomes can be predicted using a classifier that utilizes an ROC curve?\n",
      "114 What are type I and type II errors in statistical hypothesis testing?\n",
      "114 When is a correct hypothesis wrongly rejected, and when is an incorrect hypothesis wrongly accepted?\n",
      "114 What are the two main kinds of errors that occur during statistical hypothesis testing?\n",
      "115 What is the core concept behind predictive modeling?\n",
      "115 How do predictive models utilize historical data to make forecasts?\n",
      "115 What algorithms are commonly used in training predictive models?\n",
      "116 What are some essential Python libraries for machine learning tasks?\n",
      "116 Which libraries are commonly used in data manipulation, numerical operations, and scientific computing within ML?\n",
      "116 Can you name the primary libraries used for implementing machine learning algorithms and deep learning models?\n",
      "117 What is a statistical model used for?\n",
      "117 How are models constructed in data analysis?\n",
      "117 What role do models play in decision-making?\n",
      "118 How is K-fold cross-validation typically implemented?\n",
      "118 What is the primary goal when using K-fold cross-validation in machine learning?\n",
      "118 Describe a scenario where K-fold cross-validation would be particularly useful.\n",
      "119 What strategies can be employed to address the cold start problem?\n",
      "119 How do recommendation systems provide personalized recommendations for new users or items with sparse data?\n",
      "119 What methods enable recommendation systems to recommend items based on user attributes and similarities?\n",
      "120 What is the purpose of classification in machine learning?\n",
      "120 How does a model determine the category of a new observation?\n",
      "120 What type of prediction does a classifier make based on training data?\n",
      "121 What strategies can be employed to address binary classification imbalance?\n",
      "121 How can we improve classifier performance in minority class identification?\n",
      "121 What techniques are used to rebalance class distribution and ensure reliable predictions?\n",
      "122 What is a chatbot's primary function?\n",
      "122 How does a chatbot interact with human users?\n",
      "122 What are the main purposes of using a chatbot?\n",
      "123 What terms are used interchangeably to describe factors that may affect an outcome?\n",
      "123 List variables that can influence outcomes in statistical analysis.\n",
      "123 What factors are essential for understanding relationships and making predictions?\n",
      "124 What planning technique in AI allows for flexible order of operations?\n",
      "124 How does partial order planning enable more complex planning scenarios?\n",
      "124 In what context is the exact sequence of actions not predetermined?\n",
      "125 What algorithms are used for hyperparameter optimization in machine learning?\n",
      "125 List different methods to find optimal hyperparameters for a model.\n",
      "125 Which search strategies can be employed to optimize hyperparameters?\n",
      "126 What tools are used for enterprise data integration in ETL processes?\n",
      "126 Which software is utilized for data management and integration during the ETL process?\n",
      "126 How do you handle large volumes of data using an ETL tool?\n",
      "127 What are the two main approaches to combining models?\n",
      "127 How do parallel methods like Bagging improve predictions?\n",
      "127 What is the key difference between sequential and parallel ensemble methods?\n",
      "128 What is a simple machine learning algorithm used for classification and regression tasks?\n",
      "128 How does KNN classify query points based on their neighbors?\n",
      "128 What assumption does KNN rely on to make predictions?\n",
      "129 What geometric concept is used in SVM to find the optimal hyperplane?\n",
      "129 How does the convex hull relate to data separation in machine learning?\n",
      "129 In what context is the maximum margin of a hyperplane maximized?\n",
      "130 What type of model is logistic regression, despite its name?\n",
      "130 How does logistic regression handle classification tasks?\n",
      "130 Is the decision boundary in logistic regression linear or non-linear?\n",
      "131 What types of RNNs address vanishing gradient problem?\n",
      "131 List architectures enhancing RNN capabilities for sequential data processing.\n",
      "131 Which variants cater to different requirements in NLP and sequential modeling?\n",
      "132 What is the primary characteristic of weak AI?\n",
      "132 How does weak AI differ from AGI in terms of cognitive abilities?\n",
      "132 List three examples of applications where weak AI can be effectively used.\n",
      "133 What is TF/IDF vectorization used for?\n",
      "133 How does TF/IDF convert text into numerical vectors?\n",
      "133 What tasks can benefit from TF/IDF analysis?\n",
      "134 What parameters are set before model training?\n",
      "134 How do these parameters influence model performance and behavior?\n",
      "134 Why is careful selection and tuning of these parameters necessary?\n",
      "135 What are the three main loop control statements in programming?\n",
      "135 How do you skip to the next iteration in a loop?\n",
      "135 What happens when you use the break statement in a loop?\n",
      "136 What happens to CNN predictions if an image is rotated?\n",
      "136 How do rotations affect a CNN's performance on images?\n",
      "136 Can CNNs handle rotated input images without affecting their predictions?\n",
      "137 What statistical method is used to estimate English language complexity?\n",
      "137 How can letter sequences in English be analyzed for probabilistic insights?\n",
      "137 What technique evaluates the information content of the English language?\n",
      "138 What is the process of breaking down sentences to understand their grammatical structure?\n",
      "138 How are sentences analyzed to identify relationships between words in NLP tasks?\n",
      "138 What is crucial for understanding natural language and other related NLP activities?\n",
      "139 What statistical techniques are used in econometrics?\n",
      "139 How does econometrics help understand economic relationships?\n",
      "139 What is the purpose of using historical data in econometrics?\n",
      "140 What are the distinct purposes of % and / operators in Python?\n",
      "140 How does floor division, represented by // operator, differ from regular division in Python?\n",
      "140 In what scenarios would you use the % operator to compute remainders in Python?\n",
      "141 What is Jupyter Notebook?\n",
      "141 Describe an interactive computing environment.\n",
      "141 List programming languages supported by Jupyter.\n",
      "142 What is the Bag of Words model used for?\n",
      "142 How does the Bag of Words model simplify text?\n",
      "142 What are the benefits of using the Bag of Words model in text classification?\n",
      "143 What technique in computer vision allows a model to leverage knowledge from one task on another related task?\n",
      "143 How is a pre-trained model adapted for use in a new, but related, computer vision task?\n",
      "143 In the context of computer vision, what does it mean to 'repurpose' a trained model?\n",
      "144 What is PCA used for in data analysis?\n",
      "144 How does PCA simplify complex datasets?\n",
      "144 What are the benefits of using PCA in various fields?\n",
      "145 What algorithm does Facebook use for face verification?\n",
      "145 How does DeepFace classify faces accurately?\n",
      "145 What is the primary method used by Facebook to detect and align faces?\n",
      "146 What are the main purposes of OLAP and OLTP systems?\n",
      "146 How do OLTP and OLAP databases differ in terms of structure?\n",
      "146 What type of data is typically handled by OLTP versus OLAP systems?\n",
      "147 What type of models extend traditional linear regression to accommodate non-normal distributions?\n",
      "147 How do generalized linear models differ from traditional linear regression?\n",
      "147 Which types of data can be analyzed using generalized linear models?\n",
      "148 What insights does data profiling provide about individual data attributes?\n",
      "148 How does data mining differ from data profiling in terms of analysis goals?\n",
      "148 What types of patterns and relations can be uncovered through data mining?\n",
      "149 What is Apache OpenNLP?\n",
      "149 Describe a machine learning-based toolkit for processing natural language text.\n",
      "149 List common NLP tasks supported by Apache OpenNLP.\n",
      "150 What is the minimum effect size a statistical test can identify?\n",
      "150 What is the smallest difference a statistical test can reliably detect?\n",
      "150 What is the threshold for an effect to be considered statistically significant?\n",
      "151 What methods can help prevent overfitting and underfitting?\n",
      "151 How can you ensure a model's performance is not overly dependent on the training data?\n",
      "151 What techniques can be applied to prevent a model from becoming too complex?\n",
      "152 What does an S curve represent graphically?\n",
      "152 Describe the phases of growth in an S-curve.\n",
      "152 How is an S-curve used for trend analysis and forecasting?\n",
      "153 What are some popular machine learning libraries?\n",
      "153 Which frameworks support deep learning models?\n",
      "153 What environments enable AI model development?\n",
      "154 What systems assist radiologists in differentiating between benign and malignant findings?\n",
      "154 How do computer-aided diagnosis (CADx) systems aid medical image interpretation?\n",
      "154 In what way do CADx systems support the work of radiologists?\n",
      "155 What is TensorFlow, a machine learning framework?\n",
      "155 Describe the features of TensorFlow for building AI models.\n",
      "155 What capabilities does TensorFlow offer for deep learning and distributed computing?\n",
      "156 What does the survival function represent?\n",
      "156 What is another name for the survival curve?\n",
      "156 What does the survival function estimate at each time point?\n",
      "157 How does one efficiently compute inner products between data pairs in a higher-dimensional space?\n",
      "157 What enables algorithms to operate effectively with lower-dimensional data?\n",
      "157 In what way can high-dimensional calculations be made feasible with lower-dimensional data?\n",
      "158 What is ETL process in data integration?\n",
      "158 Describe the steps involved in Extract, Transform, Load process.\n",
      "158 How does ETL help in preparing data for analysis?\n",
      "159 What statistical technique is used to evaluate model generalization?\n",
      "159 How does cross-validation partition data for evaluation?\n",
      "159 What is the purpose of using a test set in cross-validation?\n",
      "160 What is the purpose of a classification threshold in logistic regression?\n",
      "160 How does the classification threshold affect class label assignment in probabilistic classifiers?\n",
      "160 What is the significance of setting a specific cutoff point for predicted probabilities?\n",
      "161 What is cross-validation used for in machine learning?\n",
      "161 How does cross-validation evaluate a statistical model's generalizability?\n",
      "161 Can you describe how cross-validation partitions data to test a model's predictive ability?\n",
      "162 What types of statistical biases can lead to incorrect conclusions?\n",
      "162 Can you give an example of a situation where sampling bias occurs?\n",
      "162 How does confirmation bias affect the accuracy of data analysis?\n",
      "163 What is COSHH in Hadoop?\n",
      "163 How does COSHH scheduling work?\n",
      "163 What are the resource characteristics considered by COSHH?\n",
      "164 What are data points that deviate significantly from a dataset's general trend?\n",
      "164 How can outliers indicate measurement errors or rare events in data?\n",
      "164 Why is it essential to identify and handle outliers in data analysis?\n",
      "165 What steps are taken to ensure data accuracy?\n",
      "165 How can data inconsistencies be identified?\n",
      "165 What validation checks help prevent errors in analysis?\n",
      "166 What algorithm adjusts learning rates for each parameter individually?\n",
      "166 How does AdaGrad scale parameters according to past gradients?\n",
      "166 What is the purpose of using different learning rates in Adagrad?\n",
      "167 What type of algorithm generates Amazon's 'Customers who purchased this item also bought...' suggestions?\n",
      "167 How do Amazon's product recommendations work without needing to know the features of items themselves?\n",
      "167 What technique does Amazon use to suggest products based on user behavior and transaction history?\n",
      "168 What parameter is used to determine the number of trees in a random forest?\n",
      "168 How can you initially select a reasonable number of trees for a random forest model?\n",
      "168 At what point should you stop adding trees to a random forest model?\n",
      "169 What does Q-Learning entail in reinforcement learning?\n",
      "169 How does an agent learn optimal actions using Q-Learning?\n",
      "169 In what way does Q-Learning enable an agent to discover the best course of action?\n",
      "170 What are the primary differences between supervised and unsupervised learning in data science?\n",
      "170 How does labeled data contribute to prediction and classification in machine learning?\n",
      "170 Can you describe a scenario where patterns and relationships are discovered without prior knowledge of the outcome?\n",
      "171 What is the primary goal of recommendation algorithms?\n",
      "171 How do recommendation algorithms use historical data to make predictions?\n",
      "171 In what types of platforms are recommendation algorithms commonly used?\n",
      "172 What are the benefits of creating detailed flowcharts for business processes?\n",
      "172 How can mapping out business steps improve efficiency?\n",
      "172 What is the purpose of identifying and streamlining workflow in a business process?\n",
      "173 What binary format transformation is used for categorical variables?\n",
      "173 How are categories represented in one-hot encoding?\n",
      "173 What ensures interpretability of machine learning models when dealing with categorical data?\n",
      "174 What statistical concept assesses alignment between observed data and expected patterns?\n",
      "174 How does one validate the accuracy of a statistical model in relation to real-world data?\n",
      "174 What is the purpose of goodness of fit in evaluating the effectiveness of statistical models?\n",
      "175 What mathematical formula or algorithm is used to process sample data?\n",
      "175 How does an estimator produce a value from sample data?\n",
      "175 What is the purpose of using an estimator in statistical analysis?\n",
      "176 What is the purpose of comparing probabilities between two groups?\n",
      "176 How does relative risk differ from odds ratios and hazard ratios?\n",
      "176 Why is understanding relative risk crucial in epidemiology and clinical research?\n",
      "177 What is a fundamental unit used in neural networks for binary classification?\n",
      "177 Describe an algorithm that makes predictions using a linear function and weights.\n",
      "177 What are the inputs weighed with to make predictions in a perceptron?\n",
      "178 What is the purpose of Information Retrieval?\n",
      "178 How does Information Extraction differ from database searches?\n",
      "178 What are the primary functions of Information Extraction in text analysis?\n",
      "179 What is the primary framework for text engineering?\n",
      "179 Describe the modular design of a comprehensive NLP toolset.\n",
      "179 What features allow for the integration of additional processing resources in text analysis?\n",
      "180 What are some practical uses of natural language processing?\n",
      "180 How does NLP contribute to speech recognition technology?\n",
      "180 In what ways can virtual assistants benefit from NLP capabilities?\n",
      "181 What types of data modification occur in a Type 1 SCD?\n",
      "181 How does a Type 2 SCD preserve historical information?\n",
      "181 In what way do Type 3 SCDS track changes to the original data?\n",
      "182 What strategy optimizes network traffic in distributed systems like Hadoop?\n",
      "182 How does data storage across multiple racks improve reliability in distributed systems?\n",
      "182 In what way do distributed systems like Hadoop benefit from organizing data storage efficiently?\n",
      "183 What tools are used for training NLP models?\n",
      "183 Which libraries are commonly used in NLP model development?\n",
      "183 List the primary tools utilized in deep learning for natural language processing.\n",
      "184 What is the initial step in setting the learning rate for machine learning algorithms?\n",
      "184 How does the learning rate impact model convergence and stability?\n",
      "184 What is the key factor to consider when adjusting the learning rate during training?\n",
      "185 What is knowledge engineering in AI?\n",
      "185 How do knowledge engineers capture human expertise?\n",
      "185 What techniques are used to encode domain-specific knowledge?\n",
      "186 What techniques does XGBoost use to balance bias and variance?\n",
      "186 How does XGBoost combine weak models to improve predictions?\n",
      "186 What methods does XGBoost employ to reduce overfitting and increase model diversity?\n",
      "187 What statistical properties must variables have for linear regression to hold?\n",
      "187 Under what conditions does linear regression assume errors are distributed?\n",
      "187 Which type of correlation between predictors would invalidate linear regression?\n",
      "188 How can you transform a pandas DataFrame's structure?\n",
      "188 What techniques are used to change the shape of a pandas DataFrame?\n",
      "188 In what ways can you pivot or tidy up a pandas DataFrame?\n",
      "189 What techniques prevent overfitting in neural networks?\n",
      "189 How do regularizers like dropout contribute to model simplicity?\n",
      "189 What is the purpose of disabling neurons randomly during training?\n",
      "190 What statistical technique is used to analyze the relationship between a continuous dependent variable and a categorical independent variable?\n",
      "190 How does ANCOVA extend the traditional ANOVA method in analyzing relationships between variables?\n",
      "190 What is the primary purpose of incorporating covariates into an analysis using ANCOVA?\n",
      "191 What does true positive mean in terms of diagnostic accuracy?\n",
      "191 How do true positives relate to a test's ability to detect a condition?\n",
      "191 What is the significance of true positives in evaluating a medical test?\n",
      "192 What is the primary goal of managing model complexity in machine learning?\n",
      "192 How can a balanced model be achieved to prevent underfitting and overfitting?\n",
      "192 What are the consequences of having high bias or high variance models on predictive performance?\n",
      "193 What is meant by marginal quantities in data analysis?\n",
      "193 How does marginalization help in understanding relationships between variables?\n",
      "193 What is an example of how marginal estimates are used to obtain overall probabilities?\n",
      "194 What is the role of a library's index in HDFS?\n",
      "194 In HDFS, what component keeps track of file locations?\n",
      "194 How does the NameNode function in terms of file storage?\n",
      "195 What is a reference point for comparing model performance?\n",
      "195 In machine learning, what serves as a simple starting model?\n",
      "195 What establishes a standard against which more complex models are compared?\n",
      "196 What enables neural networks to learn complex relationships between inputs and outputs?\n",
      "196 How do activation functions enhance model capacity and expressiveness in neural networks?\n",
      "196 Why is nonlinearity necessary for neural networks to capture intricate patterns?\n",
      "197 What search strategy involves running two simultaneous searches?\n",
      "197 How can we potentially find a solution faster than a unidirectional search?\n",
      "197 What is the main goal of a bidirectional search algorithm?\n",
      "198 What happens when gradient descent methods are applied with different initial conditions?\n",
      "198 Can gradient descent methods converge to the same point under varying cost functions?\n",
      "198 How do starting conditions affect the convergence of gradient descent methods?\n",
      "199 What is word2vec used for?\n",
      "199 How does word2vec predict surrounding words?\n",
      "199 What type of embeddings does word2vec produce?\n",
      "200 What type of models learn data categories?\n",
      "200 How do discriminative models compare to generative models in classification tasks?\n",
      "200 What is the primary distinction between generative and discriminative models?\n"
     ]
    }
   ],
   "source": [
    "for doc_id, questions in results.items():\n",
    "    for q in questions:\n",
    "        #final_results.append((doc_id, q))\n",
    "        print(doc_id, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2bcc6347-80af-499e-9ee6-d346f0e9f067",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = []\n",
    "\n",
    "for doc_id, questions in results.items():\n",
    "    for q in questions:\n",
    "        final_results.append((doc_id, q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0037e60a-e338-481e-9845-e3161c881ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 'What happens when a machine learning model is too simple?')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3e1fac17-dccb-46d7-bade-50166dafbd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(final_results, columns=['id', 'question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7552861b-a191-4252-9704-b788d117f4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What happens when a machine learning model is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>How does overfitting affect a model's performa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Can a model be too complex, and if so, what ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>What are the implications of a test result tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>How does a false indication of a condition's a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           question\n",
       "0   1  What happens when a machine learning model is ...\n",
       "1   1  How does overfitting affect a model's performa...\n",
       "2   1  Can a model be too complex, and if so, what ar...\n",
       "3   2  What are the implications of a test result tha...\n",
       "4   2  How does a false indication of a condition's a..."
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c64131b0-9cca-488b-a819-320bcd5f9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('../data/ground-truth-retrieval.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "df4e5a91-a049-432d-b5f4-cc4320c27a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,question\n",
      "1,What happens when a machine learning model is too simple?\n",
      "1,How does overfitting affect a model's performance on new data?\n",
      "1,\"Can a model be too complex, and if so, what are the consequences?\"\n",
      "2,What are the implications of a test result that incorrectly suggests a condition's presence?\n",
      "2,How does a false indication of a condition's absence impact diagnosis and treatment?\n",
      "2,Can you describe a situation where a medical test fails to detect an actual condition?\n",
      "3,What type of studies are conducted after a drug or medical product is made available to the general public?\n",
      "3,What is the primary goal of Phase IV studies in terms of monitoring a product's safety and efficacy?\n",
      "3,How do Phase IV studies contribute to informed decision-making about a product's continued use?\n"
     ]
    }
   ],
   "source": [
    "!head ../data/ground-truth-retrieval.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f87a34-e06b-4393-95ff-4d587c09afd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4027e4ca-20db-4198-adad-e0e2912c4464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f8dfa-0528-4827-a7d2-5eee0f5e3c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
